{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio: construir un modelo de regresión logística simple\n",
    "\n",
    "En este ejercicio, ajustaremos un modelo de regresión logística simple que intentará predecir la posibilidad de una avalancha.\n",
    "\n",
    "Recuerde que la regresión logística ajusta una curva en forma de s a los datos, en lugar de una línea recta, y podemos usar esto para calcular la probabilidad de un resultado binario.\n",
    "\n",
    "Visualización de datos\n",
    "\n",
    "Comencemos este ejercicio cargando y echando un vistazo a nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "!pip install statsmodels\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/avalanche.csv\n",
    "\n",
    "#Import the data from the .csv file\n",
    "dataset = pandas.read_csv('avalanche.csv', delimiter=\"\\t\")\n",
    "\n",
    "#Let's have a look at the data\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploración de datos\n",
    "\n",
    "El campo de avalanchas es nuestro objetivo. Un valor de 1 significa que ocurrió una avalancha en las condiciones descritas por las características, mientras que un valor de 0 significa que no ocurrió ninguna avalancha. Dado que nuestros objetivos solo pueden ser 0 o 1, llamamos a esto un modelo de clasificación binaria.\n",
    "\n",
    "Ahora, tracemos las relaciones entre cada característica y los valores objetivo. Eso nos ayuda a comprender qué características tienen más probabilidades de influir en los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"surface_hoar\", show=True)\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"fresh_thickness\", show=True)\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"weak_layers\", show=True)\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"no_visitors\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar que:\n",
    "\n",
    "Para fresh_thickness los resultados son muy similares. Esto significa que las variaciones en sus valores no están fuertemente correlacionadas con los resultados.\n",
    "\n",
    "Las variaciones en los valores para las capas débiles y sin visitantes parecen correlacionarse con un mayor número de resultados de avalancha y, por lo tanto, debemos asignar más importancia a estas características.\n",
    "\n",
    "Las diferencias entre los días de avalancha y sin avalancha son pequeñas y no hay un factor claro de problemas. Las capas débiles parecen un buen punto de partida, ya que están relacionadas con la mayor variación en los resultados.\n",
    "\n",
    "Construcción de un modelo de regresión logística simple\n",
    "Ahora construiremos y entrenaremos un modelo para predecir la posibilidad de que ocurra una avalancha basándonos únicamente en la cantidad de capas débiles de nieve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we import a function that splits datasets according to a given ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset in an 70/30 train/test ratio. \n",
    "train, test = train_test_split(dataset, test_size=0.3, random_state=2)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, entrenemos nuestro modelo, usando el conjunto de datos de entrenamiento que acabamos de crear (observe que las capas débiles serán la única función utilizada para determinar el resultado):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "\n",
    "# Perform logistic regression.\n",
    "model = smf.logit(\"avalanche ~ weak_layers\", train).fit()\n",
    "\n",
    "print(\"Model trained\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después del entrenamiento, podemos imprimir un resumen del modelo con información muy detallada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que el coeficiente positivo para las capas_débiles significa que un valor más alto significa una mayor probabilidad de que se produzca una avalancha."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando nuestro modelo\n",
    "Ahora podemos usar nuestro modelo entrenado para hacer predicciones y estimar probabilidades.\n",
    "\n",
    "Elijamos las primeras cuatro ocurrencias en nuestro conjunto de prueba e imprimamos la probabilidad de una avalancha para cada una de ellas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict to get a probability\n",
    "\n",
    "# get first 3 samples from dataset\n",
    "samples = test[\"weak_layers\"][:4]\n",
    "\n",
    "# use the model to get predictions as possibilities\n",
    "estimated_probabilities = model.predict(samples)\n",
    "\n",
    "# Print results for each sample\n",
    "for sample, pred in zip(samples,estimated_probabilities):\n",
    "    print(f\"A weak_layer with value {sample} yields a {pred * 100:.2f}% chance of an avalanche.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracemos un modelo para entender esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model\n",
    "# Show a graph of the result\n",
    "predict = lambda x: model.predict(pandas.DataFrame({\"weak_layers\": x}))\n",
    "\n",
    "graphing.line_2D([(\"Model\", predict)],\n",
    "                 x_range=[-20,40],\n",
    "                 label_x=\"weak_layers\", \n",
    "                 label_y=\"estimated probability of an avalanche\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La línea traza la función de la probabilidad de una avalancha sobre el número de capas débiles; Tenga en cuenta que cuanto más débiles sean las capas, más probable es que ocurra una avalancha. Esta trama puede parecer un poco confusa por dos razones.\n",
    "\n",
    "En primer lugar, la curva puede hacer predicciones de infinito negativo a positivo, pero solo tenemos datos para 0 - 10 capas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Minimum number of weak layers:\", min(train.weak_layers))\n",
    "print(\"Maximum number of weak layers:\", max(train.weak_layers))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto se debe a que los modelos de regresión logística permiten predicciones fuera del rango de valores que han visto y, a veces, lo hacen bastante bien.\n",
    "\n",
    "La segunda razón por la que la trama es confusa es que con 0 capas, todavía existe cierto riesgo de avalancha. Del mismo modo, con 10 capas, no hay un 100 % de riesgo de avalancha. Esto está realmente en línea con los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get actual rates of avalanches at 0 years\n",
    "avalanche_outcomes_for_0_layers = train[train.weak_layers == 0].avalanche\n",
    "print(\"Average rate of avalanches for 0 weak layers of snow\", np.average(avalanche_outcomes_for_0_layers))\n",
    "\n",
    "# Get actual rates of avalanches at 10 years\n",
    "avalanche_outcomes_for_10_layers = train[train.weak_layers == 10].avalanche\n",
    "print(\"Average rate of avalanches for 10 weak layers of snow\", np.average(avalanche_outcomes_for_10_layers))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Nuestro modelo realmente está haciendo un buen trabajo! Es solo que las avalanchas no solo son causadas por capas débiles de nieve. Si queremos hacerlo mejor, probablemente debamos pensar en incluir otra información en el modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Umbrales de clasificación o decisión\n",
    "\n",
    "Para devolver una categoría binaria (Verdadero = \"avalancha\", Falso = \"sin avalancha\") necesitamos definir un valor de Umbral de clasificación. Cualquier probabilidad por encima de ese umbral se devuelve como categoría positiva, mientras que los valores por debajo se devolverán como categoría negativa.\n",
    "\n",
    "Veamos qué sucede si establecemos nuestro umbral en 0.5 (lo que significa que nuestro modelo devolverá True cada vez que calcule una probabilidad superior al 50% de que ocurra una avalancha):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold to get an absolute value\n",
    "threshold = 0.5\n",
    "\n",
    "# Add classification to the samples we used before\n",
    "for sample, pred in list(zip(samples,estimated_probabilities)):\n",
    "    print(f\"A weak_layer with value {sample} yields a chance of {pred * 100:.2f}% of an avalanche. Classification = {pred > threshold}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que un umbral de 0,5 es solo un punto de partida que debe ajustarse según los datos que estamos tratando de clasificar.\n",
    "\n",
    "Rendimiento en el conjunto de prueba\n",
    "Ahora usemos nuestro conjunto de datos de prueba para realizar una evaluación rápida de cómo le fue al modelo. Por ahora, solo veremos con qué frecuencia predijimos correctamente si habría una avalancha o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the mdel predictions using the threshold\n",
    "predictions = model.predict(test) > threshold\n",
    "\n",
    "# Compare the predictions to the actual outcomes in the dataset\n",
    "accuracy = np.average(predictions == test.avalanche)\n",
    "\n",
    "# Print the evaluation\n",
    "print(f\"The model correctly predicted outcomes {accuracy * 100:.2f}% of time.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las avalanchas son difíciles de detectar, pero lo estamos haciendo bien. Sin embargo, es difícil decir exactamente qué tipo de errores está cometiendo nuestro modelo. Nos centraremos en esto en el siguiente ejercicio.\n",
    "\n",
    "Resumen\n",
    "\n",
    "En esta unidad tratamos los siguientes temas:\n",
    "\n",
    "Uso de exploración de datos para comprender qué características tienen una correlación más fuerte con los resultados<br>\n",
    "Construcción de un modelo de regresión logística simple<br>\n",
    "Uso del modelo entrenado para predecir probabilidades<br>\n",
    "Uso de umbrales para asignar probabilidades a clases binarias<br>\n",
    "Cómo utilizar un conjunto de prueba para medir el rendimiento del modelo"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
