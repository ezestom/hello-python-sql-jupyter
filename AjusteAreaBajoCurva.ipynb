{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio: Sintonice el área bajo la curva\n",
    "\n",
    "En este ejercicio, crearemos y compararemos dos modelos usando curvas ROC y ajustaremos uno usando el área bajo la curva (AUC).\n",
    "\n",
    "El objetivo de nuestros modelos es identificar si cada elemento detectado en la montaña es un caminante (verdadero) o un árbol (falso). Trabajaremos con nuestra función de movimiento aquí. Vamos a ver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "!pip install statsmodels\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/hiker_or_tree.csv\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/m2d_make_roc.py\n",
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "import sklearn.model_selection\n",
    "\n",
    "# Load our data from disk\n",
    "df = pandas.read_csv(\"hiker_or_tree.csv\", delimiter=\"\\\\t\")\n",
    "\n",
    "# Remove features we no longer want\n",
    "del df[\"height\"]\n",
    "del df[\"texture\"]\n",
    "\n",
    "# Split into train and test\n",
    "train, test =  sklearn.model_selection.train_test_split(df, test_size=0.5, random_state=1)\n",
    "\n",
    "# Graph our feature\n",
    "graphing.multiple_histogram(test, label_x=\"motion\", label_group=\"is_hiker\", nbins=12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El movimiento parece estar más asociado con los excursionistas que con los árboles, pero no perfectamente. Presumiblemente, esto se debe a que los árboles se mueven con el viento y algunos excursionistas se encuentran sentados.\n",
    "\n",
    "Un modelo de regresión logística y un bosque aleatorio\n",
    "Entrenemos el mismo modelo de regresión logística que usamos en el ejercicio anterior, así como un modelo de bosque aleatorio. Ambos intentarán predecir qué objetos son excursionistas.\n",
    "\n",
    "Primero la regresión logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# This is a helper method that reformats the data to be compatible\n",
    "# with this particular logistic regression model \n",
    "prep_data = lambda x:  numpy.column_stack((numpy.full(x.shape, 1), x))\n",
    "\n",
    "# Train a logistic regression model to predict hiker based on motion\n",
    "lr_model = statsmodels.api.Logit(train.is_hiker, prep_data(train.motion), add_constant=True).fit()\n",
    "\n",
    "# Assess its performance\n",
    "# -- Train\n",
    "predictions = lr_model.predict(prep_data(train.motion)) > 0.5\n",
    "train_accuracy = accuracy_score(train.is_hiker, predictions)\n",
    "\n",
    "# -- Test\n",
    "predictions = lr_model.predict(prep_data(test.motion)) > 0.5\n",
    "test_accuracy = accuracy_score(test.is_hiker, predictions)\n",
    "\n",
    "print(\"Train accuracy\", train_accuracy)\n",
    "print(\"Test accuracy\", test_accuracy)\n",
    "\n",
    "# Plot the model\n",
    "predict_with_logistic_regression = lambda x: lr_model.predict(prep_data(x))\n",
    "graphing.scatter_2D(test, label_x=\"motion\", label_y=\"is_hiker\", title=\"Logistic Regression\", trendline=predict_with_logistic_regression)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora nuestro modelo de bosque aleatorio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a random forest model with 50 trees\n",
    "random_forest = RandomForestClassifier(random_state=2,\n",
    "                                       verbose=False)\n",
    "\n",
    "# Train the model\n",
    "random_forest.fit(train[[\"motion\"]], train.is_hiker)\n",
    "\n",
    "# Assess its performance\n",
    "# -- Train\n",
    "predictions = random_forest.predict(train[[\"motion\"]])\n",
    "train_accuracy = accuracy_score(train.is_hiker, predictions)\n",
    "\n",
    "# -- Test\n",
    "predictions = random_forest.predict(test[[\"motion\"]])\n",
    "test_accuracy = accuracy_score(test.is_hiker, predictions)\n",
    "\n",
    "\n",
    "# Train and test the model\n",
    "print(\"Random Forest Performance:\")\n",
    "print(\"Train accuracy\", train_accuracy)\n",
    "print(\"Test accuracy\", test_accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos modelos tienen un rendimiento similar, pero no idéntico, en el conjunto de prueba en términos de precisión.\n",
    "\n",
    "Crear gráficos ROC\n",
    "Vamos a crear curvas ROC para estos modelos. Para ello, simplemente importaremos el código de los últimos ejercicios para poder centrarnos en lo que nos gustaría aprender aquí. Si necesita un repaso sobre cómo se hicieron, vuelva a leer el último ejercicio.\n",
    "\n",
    "Tenga en cuenta que hemos hecho un ligero cambio. Ahora nuestro método produce tanto un gráfico como la tabla de números que usamos para crear el gráfico.\n",
    "\n",
    "Primero veamos el modelo de regresión logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from m2d_make_roc import create_roc_curve # import our previous ROC code\n",
    "\n",
    "fig, thresholds_lr = create_roc_curve(predict_with_logistic_regression, test, \"motion\")\n",
    "\n",
    "# Uncomment the line below if you would like to see the area under the curve\n",
    "#fig.update_traces(fill=\"tozeroy\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Show the table of results\n",
    "thresholds_lr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que nuestro modelo funciona mejor que el azar (no es una línea diagonal). Nuestra tabla muestra la tasa de falsos positivos (fpr) y la tasa de verdaderos positivos (tpr) para cada umbral.\n",
    "\n",
    "Repitamos esto para nuestro modelo de bosque aleatorio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry about this lambda function. It simply reorganizes \n",
    "# the data into the shape expected by the random forest model, \n",
    "# and calls predict_proba, which gives us predicted probabilities\n",
    "# that the label is 'hiker'\n",
    "predict_with_random_forest = lambda x: random_forest.predict_proba(numpy.array(x).reshape(-1, 1))[:,1]\n",
    "\n",
    "# Create the ROC curve\n",
    "fig, thresholds_rf = create_roc_curve(predict_with_random_forest, test, \"motion\")\n",
    "\n",
    "# Uncomment the line below if you would like to see the area under the curve\n",
    "#fig.update_traces(fill=\"tozeroy\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Show the table of results\n",
    "thresholds_lr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Área bajo la curva\n",
    "\n",
    "Nuestros modelos se parecen bastante. ¿Qué modelo creemos que es mejor? Usemos el área bajo la curva (AUC) para compararlos. Deberíamos esperar un número mayor que 0,5, porque ambos modelos son mejores que el azar, pero menor que 1, porque no son perfectos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Logistic regression\n",
    "print(\"Logistic Regression AUC:\", roc_auc_score(test.is_hiker, predict_with_logistic_regression(test.motion)))\n",
    "\n",
    "# Random Forest\n",
    "print(\"Random Forest AUC:\", roc_auc_score(test.is_hiker, predict_with_random_forest(test.motion)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por un margen muy pequeño, el modelo de regresión logística se destaca.\n",
    "\n",
    "Recuerde, esto no significa que el modelo de regresión logística siempre funcionará mejor que el bosque aleatorio. Significa que el modelo de regresión logística es una opción ligeramente mejor para este tipo de datos, y probablemente depende un poco menos de tener los umbrales de decisión perfectos elegidos.\n",
    "\n",
    "Ajuste del umbral de decisión\n",
    "También podemos usar nuestra información de ROC para encontrar los mejores umbrales para usar. Solo trabajaremos con nuestro modelo de bosque aleatorio para esta parte.\n",
    "\n",
    "Primero, echemos un vistazo a la tasa de verdaderos y falsos positivos con el umbral predeterminado de 0,5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out its expected performance at the default threshold of 0.5\n",
    "# We previously obtained this information when we created our graphs\n",
    "row_of_0point5 = thresholds_rf[thresholds_rf.threshold == 0.5]\n",
    "print(\"TPR at threshold of 0.5:\", row_of_0point5.tpr.values[0])\n",
    "print(\"FPR at threshold of 0.5:\", row_of_0point5.fpr.values[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos esperar que, cuando se vean excursionistas reales, tengamos un 86% de posibilidades de identificarlos. Cuando se ven árboles o excursionistas, tenemos un 16 % de posibilidades de identificarlos como excursionistas.\n",
    "\n",
    "Digamos que para nuestra situación particular, consideramos tan importante obtener un verdadero positivo como evitar un falso positivo. No queremos ignorar a los excursionistas en la montaña, pero tampoco queremos enviar a nuestro equipo a condiciones peligrosas sin ningún motivo.\n",
    "\n",
    "Podemos encontrar el mejor umbral creando nuestro propio sistema de puntuación y viendo qué umbral obtendría el mejor resultado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how good each threshold is from our TPR and FPR. \n",
    "# Our criteria is that the TPR is as high as possible and \n",
    "# the FPR is as low as possible. We consider them equally important\n",
    "scores = thresholds_rf.tpr - thresholds_rf.fpr\n",
    "\n",
    "# Find the entry with the lowest score according to our criteria\n",
    "index_of_best_score = numpy.argmax(scores)\n",
    "best_threshold = thresholds_rf.threshold[index_of_best_score]\n",
    "print(\"Best threshold:\", best_threshold)\n",
    "\n",
    "# Print out its expected performance\n",
    "print(\"TPR at this threshold:\", thresholds_rf.tpr[index_of_best_score])\n",
    "print(\"FPR at this threshold:\", thresholds_rf.fpr[index_of_best_score])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro mejor umbral, con este criterio, es 0,74, ¡no 0,5! Esto nos permitiría identificar correctamente al 83 % de los excursionistas, una ligera disminución del 86 %, pero solo identificamos erróneamente al 3,6 % de los árboles como excursionistas.\n",
    "\n",
    "Si lo desea, juegue con la forma en que calculamos nuestros puntajes aquí y vea cómo se ajusta el umbral.\n",
    "\n",
    "Resumen\n",
    "¡Eso es todo! Aquí hemos creado curvas ROC para dos modelos diferentes, utilizando el código que escribimos en el ejercicio anterior.\n",
    "\n",
    "Visualmente, eran bastante similares, y cuando los comparamos usando la métrica del área bajo la curva, encontramos que el modelo de regresión logística tenía un desempeño marginalmente mejor.\n",
    "\n",
    "Luego usamos la curva ROC para ajustar nuestro modelo de bosque aleatorio, según criterios específicos de nuestras circunstancias. Nuestros criterios muy simples de TPR - FPR nos permitieron elegir un umbral adecuado para nosotros."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
