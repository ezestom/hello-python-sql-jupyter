{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión\n",
    "Las técnicas de aprendizaje automático supervisado consisten en entrenar un modelo para que opere sobre un conjunto de características y prediga una etiqueta utilizando un conjunto de datos que incluye algunos valores de etiquetas ya conocidos. El proceso de formación ajusta las características a las etiquetas conocidas para definir una función general que pueda aplicarse a nuevas características cuyas etiquetas se desconocen y predecirlas. Se puede pensar en esta función de la siguiente manera, en la que y representa la etiqueta que queremos predecir y x representa las características que el modelo utiliza para predecirla.\n",
    "\n",
    "y=f(x)\n",
    "\n",
    "En la mayoría de los casos, x es en realidad un vector que consiste en múltiples valores de características, por lo que para ser un poco más precisos, la función podría expresarse así:\n",
    "\n",
    "y=f([x1,x2,x3,...]) \n",
    "\n",
    "El objetivo del entrenamiento del modelo es encontrar una función que realice algún tipo de cálculo con los valores x que produzca el resultado y. Para ello, aplicamos un algoritmo de aprendizaje automático que intenta ajustar los valores x a un cálculo que produzca y de forma razonablemente precisa para todos los casos del conjunto de datos de entrenamiento.\n",
    "\n",
    "Existen muchos algoritmos de aprendizaje automático para el aprendizaje supervisado, que pueden dividirse en dos tipos:\n",
    "\n",
    "Algoritmos de regresión: Algoritmos que predicen un valor y que es un valor numérico, como el precio de una casa o el número de operaciones de venta.\n",
    "Algoritmos de clasificación: Algoritmos que predicen a qué categoría, o clase, pertenece una observación. El valor y en un modelo de clasificación es un vector de valores de probabilidad entre 0 y 1, uno para cada clase, que indica la probabilidad de que la observación pertenezca a cada clase.\n",
    "En este cuaderno, nos centraremos en la regresión, utilizando un ejemplo basado en un estudio real en el que se recogieron datos de un sistema de bicicletas compartidas y se utilizaron para predecir el número de alquileres en función de la estacionalidad y las condiciones meteorológicas. Utilizaremos una versión simplificada del conjunto de datos de ese estudio."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorar los datos\n",
    "\n",
    "El primer paso en cualquier proyecto de aprendizaje automático es explorar los datos que se utilizarán para entrenar un modelo. El objetivo de esta exploración es intentar comprender las relaciones entre sus atributos; en particular, cualquier correlación aparente entre las características y la etiqueta que el modelo intentará predecir. Esto puede requerir cierto trabajo para detectar y corregir problemas en los datos (como tratar valores perdidos, errores o valores atípicos), derivar nuevas columnas de características transformando o combinando características existentes (un proceso conocido como ingeniería de características), normalizar características numéricas (valores que se pueden medir o contar) para que estén en una escala similar y codificar características categóricas (valores que representan categorías discretas) como indicadores numéricos.\n",
    "\n",
    "Empecemos cargando los datos del uso compartido de bicicletas como un DataFrame de Pandas y visualizando las primeras filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the training dataset\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/daily-bike-share.csv\n",
    "bike_data = pd.read_csv('daily-bike-share.csv')\n",
    "bike_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos constan de las siguientes columnas\n",
    "\n",
    "instant: Un identificador único de fila<br>\n",
    "dteday: La fecha en la que se observaron los datos; en este caso, los datos se recogieron diariamente, por lo que hay una fila por fecha.<br>\n",
    "estación: Un valor codificado numéricamente que indica la estación (1:invierno, 2:primavera, 3:verano, 4:otoño)<br>\n",
    "año: El año del estudio en el que se realizó la observación (el estudio tuvo lugar a lo largo de dos años: el año 0 representa 2011, y el año 1 representa 2012)<br>\n",
    "mnth: El mes natural en el que se realizó la observación (1:enero ... 12:diciembre)<br>\n",
    "holiday (vacaciones): Valor binario que indica si la observación se realizó o no en un día festivo)<br>\n",
    "día de la semana: El día de la semana en que se realizó la observación (0:domingo ... 6:sábado)<br>\n",
    "día laborable: Valor binario que indica si el día es laborable o no (no fin de semana ni festivo)<br>\n",
    "tiempo: Un valor categórico que indica la situación meteorológica (1:despejado, 2:niebla/nubes, 3:lluvia ligera/nieve, 4:lluvia fuerte/granizo/nieve/niebla)<br>\n",
    "temp: La temperatura en grados centígrados (normalizada)<br>\n",
    "atemp: La temperatura aparente en grados centígrados (normalizada).<br>\n",
    "hum: El nivel de humedad (normalizado)<br>\n",
    "windspeed: La velocidad del viento (normalizada)<br>\n",
    "alquileres: El número de alquileres de bicicletas registrados.<br>\n",
    "En este conjunto de datos, alquileres representa la etiqueta (el valor y) para cuya predicción debe entrenarse nuestro modelo. Las otras columnas son características potenciales (valores x).\n",
    "\n",
    "Como se ha mencionado anteriormente, se puede realizar un poco de ingeniería de características para combinar o derivar nuevas características. Por ejemplo, añadamos una nueva columna llamada día al marco de datos extrayendo el componente día de la columna dteday existente. La nueva columna representa el día del mes del 1 al 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data['day'] = pd.DatetimeIndex(bike_data['dteday']).day\n",
    "bike_data.head(32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, comencemos nuestro análisis de los datos examinando algunas estadísticas descriptivas clave. Podemos utilizar el método de descripción del marco de datos para generar estos para las características numéricas, así como la columna de la etiqueta de alquiler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "bike_data[numeric_features + ['rentals']].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las estadísticas revelan cierta información sobre la distribución de los datos en cada uno de los campos numéricos, incluido el número de observaciones (hay 731 registros), la media, la desviación típica, los valores mínimo y máximo y los valores de cuartil (los valores umbral para el 25%, el 50% -que también es la mediana- y el 75% de los datos). A partir de aquí, podemos ver que el número medio de alquileres diarios es de unos 848; pero hay una desviación estándar comparativamente grande, lo que indica una gran variación en el número de alquileres diarios.\n",
    "\n",
    "Podemos hacernos una idea más clara de la distribución de los valores de los alquileres visualizando los datos. Los tipos de gráficos más comunes para visualizar distribuciones de datos numéricos son los histogramas y los gráficos de caja, así que vamos a utilizar la biblioteca matplotlib de Python para crear uno de cada uno de ellos para la columna de alquileres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This ensures plots are displayed inline in the Jupyter notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Get the label column\n",
    "label = bike_data['rentals']\n",
    "\n",
    "\n",
    "# Create a figure for 2 subplots (2 rows, 1 column)\n",
    "fig, ax = plt.subplots(2, 1, figsize = (9,12))\n",
    "\n",
    "# Plot the histogram   \n",
    "ax[0].hist(label, bins=100)\n",
    "ax[0].set_ylabel('Frequency')\n",
    "\n",
    "# Add lines for the mean, median, and mode\n",
    "ax[0].axvline(label.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
    "ax[0].axvline(label.median(), color='cyan', linestyle='dashed', linewidth=2)\n",
    "\n",
    "# Plot the boxplot   \n",
    "ax[1].boxplot(label, vert=False)\n",
    "ax[1].set_xlabel('Rentals')\n",
    "\n",
    "# Add a title to the Figure\n",
    "fig.suptitle('Rental Distribution')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los gráficos muestran que el número de alquileres diarios oscila entre 0 y algo más de 3.400. Sin embargo, la media (y la mediana) del número de alquileres diarios está más cerca del extremo inferior de ese intervalo. Sin embargo, la media (y la mediana) del número de alquileres diarios está más cerca del extremo inferior de ese rango, con la mayoría de los datos entre 0 y alrededor de 2.200 alquileres. Los pocos valores por encima de esta cifra se muestran en el diagrama de caja como pequeños círculos, lo que indica que son valores atípicos, es decir, valores inusualmente altos o bajos más allá del rango típico de la mayoría de los datos.\n",
    "\n",
    "Podemos hacer el mismo tipo de exploración visual de las características numéricas. Creemos un histograma para cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram for each numeric feature\n",
    "for col in numeric_features:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    feature = bike_data[col]\n",
    "    feature.hist(bins=100, ax = ax)\n",
    "    ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
    "    ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)\n",
    "    ax.set_title(col)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las características numéricas parecen tener una distribución más normal, con la media y la mediana más cerca de la mitad del intervalo de valores, coincidiendo con los valores más frecuentes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos explorado la distribución de los valores numéricos en el conjunto de datos, pero ¿qué ocurre con las características categóricas? No se trata de números continuos en una escala, por lo que no podemos utilizar histogramas, pero podemos trazar un gráfico de barras que muestre el recuento de cada valor discreto para cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# plot a bar plot for each categorical feature count\n",
    "categorical_features = ['season','mnth','holiday','weekday','workingday','weathersit', 'day']\n",
    "\n",
    "for col in categorical_features:\n",
    "    counts = bike_data[col].value_counts().sort_index()\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    counts.plot.bar(ax = ax, color='steelblue')\n",
    "    ax.set_title(col + ' counts')\n",
    "    ax.set_xlabel(col) \n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muchas de las características categóricas muestran una distribución más o menos uniforme (lo que significa que hay aproximadamente el mismo número de filas para cada categoría). Las excepciones son\n",
    "\n",
    "Vacaciones: Hay muchos menos días festivos que no festivos.<br>\n",
    "laborables: Hay más días laborables que no laborables.<br>\n",
    "tiempo: La mayoría de los días son de categoría 1 (despejado), siendo la categoría 2 (niebla y nubes) la siguiente más común. Hay relativamente pocos días de categoría 3 (lluvia ligera o nieve) y ninguno de categoría 4 (lluvia intensa, granizo o niebla).<br>\n",
    "Ahora que sabemos algo sobre la distribución de los datos en nuestras columnas, podemos empezar a buscar relaciones entre las características y la etiqueta de alquiler que queremos poder predecir.\n",
    "\n",
    "Para las características numéricas, podemos crear gráficos de dispersión que muestren la intersección de los valores de las características y las etiquetas. También podemos calcular el estadístico de correlación para cuantificar la relación aparente.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in numeric_features:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    feature = bike_data[col]\n",
    "    label = bike_data['rentals']\n",
    "    correlation = feature.corr(label)\n",
    "    plt.scatter(x=feature, y=label)\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Bike Rentals')\n",
    "    ax.set_title('rentals vs ' + col + '- correlation: ' + str(correlation))\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados no son concluyentes, pero si se observan detenidamente los gráficos de dispersión de la temperatura y la temperatura atmosférica, se puede ver una vaga tendencia diagonal que muestra que un mayor número de alquileres tiende a coincidir con temperaturas más altas; y un valor de correlación ligeramente superior a 0,5 para ambas características apoya esta observación. Por el contrario, los gráficos correspondientes a la humedad y la velocidad del viento muestran una correlación ligeramente negativa, lo que indica que hay menos alquileres en los días en que la humedad o la velocidad del viento son elevadas.\n",
    "\n",
    "Ahora vamos a comparar las características categóricas con la etiqueta. Para ello, crearemos gráficos de caja que muestren la distribución del número de alquileres para cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a boxplot for the label by each categorical feature\n",
    "for col in categorical_features:\n",
    "    fig = plt.figure(figsize=(9, 6))\n",
    "    ax = fig.gca()\n",
    "    bike_data.boxplot(column = 'rentals', by = col, ax = ax)\n",
    "    ax.set_title('Label by ' + col)\n",
    "    ax.set_ylabel(\"Bike Rentals\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los gráficos muestran cierta variación en la relación entre los valores de algunas categorías y los alquileres. Por ejemplo, hay una clara diferencia en la distribución de los alquileres en fin de semana (día de la semana 0 ó 6) y los que se producen durante la semana laboral (día de la semana 1 a 5). Del mismo modo, hay diferencias notables en las categorías de días festivos y laborables. Hay una tendencia notable que muestra diferentes distribuciones de alquileres en los meses de primavera y verano en comparación con los meses de invierno y otoño. La categoría weathersit también parece marcar una diferencia en la distribución del alquiler. La característica del día que creamos para el día del mes muestra poca variación, lo que indica que probablemente no es predictiva del número de alquileres."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar un modelo de regresión\n",
    "\n",
    "Ahora que hemos explorado los datos, es hora de utilizarlos para entrenar un modelo de regresión que utilice las características que hemos identificado como potencialmente predictivas para predecir la etiqueta de alquiler. Lo primero que tenemos que hacer es separar las características que queremos utilizar para entrenar el modelo de la etiqueta que queremos que prediga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X, y = bike_data[['season','mnth', 'holiday','weekday','workingday','weathersit','temp', 'atemp', 'hum', 'windspeed']].values, bike_data['rentals'].values\n",
    "print('Features:',X[:10], '\\nLabels:', y[:10], sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de separar el conjunto de datos, ahora tenemos matrices numpy llamadas X que contienen las características e y que contienen las etiquetas.\n",
    "\n",
    "Podríamos entrenar un modelo utilizando todos los datos, pero es una práctica común en el aprendizaje supervisado dividir los datos en dos subconjuntos: un conjunto (normalmente más grande) con el que entrenar el modelo, y un conjunto más pequeño \"retenido\" con el que validar el modelo entrenado. Esto nos permite evaluar el rendimiento del modelo cuando se utiliza con el conjunto de datos de validación comparando las etiquetas predichas con las etiquetas conocidas. Es importante dividir los datos aleatoriamente (en lugar de, por ejemplo, tomar el primer 70% de los datos para el entrenamiento y reservar el resto para la validación). Esto ayuda a garantizar que los dos subconjuntos de datos son estadísticamente comparables (de modo que validamos el modelo con datos que tienen una distribución estadística similar a los datos con los que se entrenó).\n",
    "\n",
    "Para dividir aleatoriamente los datos, utilizaremos la función train_test_split de la biblioteca scikit-learn. Esta biblioteca es uno de los paquetes de aprendizaje automático para Python más utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data 70%-30% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print ('Training Set: %d rows\\nTest Set: %d rows' % (X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos los siguientes cuatro conjuntos de datos:\n",
    "\n",
    "X_entrenamiento: Los valores de las características que utilizaremos para entrenar el modelo<br>\n",
    "y_train: Las etiquetas correspondientes que utilizaremos para entrenar el modelo.<br>\n",
    "X_prueba: Los valores de las características que utilizaremos para validar el modelo<br>\n",
    "y_test: Las etiquetas correspondientes que utilizaremos para validar el modelo.<br>\n",
    "Ahora estamos listos para entrenar un modelo ajustando un algoritmo de regresión adecuado a los datos de entrenamiento. Utilizaremos un algoritmo de regresión lineal, un punto de partida habitual para la regresión, que intenta encontrar una relación lineal entre los valores X y la etiqueta y. El modelo resultante es una función que conceptualiza el valor de la etiqueta y. El modelo resultante es una función que define conceptualmente una línea en la que se cruzan todas las posibles combinaciones de valores X e y.\n",
    "\n",
    "En Scikit-Learn, los algoritmos de entrenamiento se encapsulan en estimadores, y en este caso utilizaremos el estimador LinearRegression para entrenar un modelo de regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Fit a linear regression model on the training set\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "print (model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluar el modelo entrenado\n",
    "\n",
    "Ahora que hemos entrenado el modelo, podemos utilizarlo para predecir los recuentos de alquileres para las características que retuvimos en nuestro conjunto de datos de validación. A continuación, podemos comparar estas predicciones con los valores reales de las etiquetas para evaluar lo bien (¡o no!) que funciona el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "np.set_printoptions(suppress=True)\n",
    "print('Predicted labels: ', np.round(predictions)[:10])\n",
    "print('Actual labels   : ' ,y_test[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparar cada predicción con su correspondiente valor real no es una forma muy eficaz de determinar lo bien que predice el modelo. Veamos si podemos obtener una indicación mejor visualizando un gráfico de dispersión que compare las predicciones con las etiquetas reales. También superpondremos una línea de tendencia para tener una idea general de la concordancia entre las etiquetas predichas y las etiquetas reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay una tendencia diagonal definida, y las intersecciones de los valores predichos y reales siguen en general la trayectoria de la línea de tendencia; pero hay bastante diferencia entre la función ideal representada por la línea y los resultados. Esta diferencia representa los residuos del modelo, es decir, la diferencia entre la etiqueta prevista cuando el modelo aplica a los datos de validación los coeficientes aprendidos durante el entrenamiento y el valor real de la etiqueta de validación. Estos residuos, evaluados a partir de los datos de validación, indican el nivel de error esperado cuando el modelo se utiliza con nuevos datos cuya etiqueta se desconoce.\n",
    "\n",
    "Puede cuantificar los residuos calculando una serie de métricas de evaluación de uso común. Nos centraremos en las tres siguientes:\n",
    "\n",
    "Error cuadrático medio (ECM): La media de las diferencias al cuadrado entre los valores predichos y los reales. Se trata de una métrica relativa en la que cuanto menor es el valor, mejor es el ajuste del modelo.<br>\n",
    "Error cuadrático medio (RMSE): La raíz cuadrada del MSE. Proporciona una medida absoluta en la misma unidad que la etiqueta (en este caso, el número de alquileres). Cuanto menor sea el valor, mejor será el modelo (en un sentido simplista, representa el número medio de alquileres en el que las predicciones son erróneas).<br>\n",
    "Coeficiente de determinación (normalmente conocido como R-cuadrado o R2): Una métrica relativa en la que cuanto mayor es el valor, mejor es el ajuste del modelo. En esencia, esta métrica representa qué parte de la varianza entre los valores predichos y reales de las etiquetas es capaz de explicar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya hemos cuantificado la capacidad de nuestro modelo para predecir el número de alquileres. Definitivamente tiene cierto poder predictivo, ¡pero probablemente podemos hacerlo mejor!\n",
    "\n",
    "Resumen\n",
    "Hemos explorado nuestros datos y ajustado un modelo de regresión básico. En el próximo cuaderno, probaremos otros algoritmos de regresión para mejorar el rendimiento.\n",
    "\n",
    "Lecturas adicionales\n",
    "Para obtener más información sobre Scikit-Learn, consulte la documentación de Scikit-Learn.https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
