{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio: curvas ROC buenas y malas\n",
    "\n",
    "En este ejercicio, crearemos algunas curvas ROC para explicar cómo se verían las curvas ROC buenas y malas.\n",
    "\n",
    "El objetivo de nuestros modelos es identificar si cada elemento detectado en la montaña es un caminante (verdadero) o un árbol (falso). Echemos un vistazo al conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "!pip install statsmodels\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/hiker_or_tree.csv\n",
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "import sklearn.model_selection\n",
    "\n",
    "# Load our data from disk\n",
    "df = pandas.read_csv(\"hiker_or_tree.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Split into train and test\n",
    "train, test =  sklearn.model_selection.train_test_split(df, test_size=0.5, random_state=1)\n",
    "\n",
    "# Graph our three features\n",
    "graphing.histogram(test, label_x=\"height\", label_colour=\"is_hiker\", show=True)\n",
    "graphing.multiple_histogram(test, label_x=\"motion\", label_group=\"is_hiker\", nbins=12, show=True)\n",
    "graphing.multiple_histogram(test, label_x=\"texture\", label_group=\"is_hiker\", nbins=12)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos tres características visuales: altura, movimiento y textura. Nuestro objetivo aquí no es optimizar un modelo, sino explorar las curvas ROC, por lo que trabajaremos solo con una a la vez.\n",
    "\n",
    "Antes de sumergirse en él, eche un vistazo a las distribuciones anteriores. Podemos ver que deberíamos poder usar la altura para separar a los excursionistas de los árboles con bastante facilidad. El movimiento será un poco más difícil, presumiblemente porque los árboles se mueven con el viento y algunos excursionistas se encuentran sentados. La textura parece muy similar para los excursionistas y los árboles.\n",
    "\n",
    "Un modelo perfecto\n",
    "¿Cómo sería un ROC perfecto? Si tuviéramos un modelo perfectamente diseñado, calcularía \"0% de probabilidad de excursionista\" cuando viera cualquier árbol y \"100% de excursionista\" cuando viera cualquier excursionista. Esto significa que, mientras el umbral de decisión fuera > 0 % y < 100 %, tendría un rendimiento perfecto. Entre estos umbrales, la tasa de verdaderos positivos siempre sería 1 y la tasa de falsos positivos siempre sería 0.\n",
    "\n",
    "No se preocupe por los umbrales de exactamente 0 y 1 (100%). En 0 estamos obligando a un modelo a devolver un valor Falso y en 1 lo estamos obligando a devolver Verdadero.\n",
    "\n",
    "Es casi imposible entrenar un modelo que sea tan perfecto, pero por el bien del aprendizaje, supongamos que lo hemos hecho, prediciendo la etiqueta is_hiker en función de la altura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api\n",
    "\n",
    "# Create a fake model that is perfect at predicting labels\n",
    "class PerfectModel:\n",
    "    def predict(self, x):\n",
    "        # The perfect model believes that hikers are all\n",
    "        # under 4m tall\n",
    "        return 1 / (1 + numpy.exp(80*(x - 4)))\n",
    "    \n",
    "model = PerfectModel()\n",
    "\n",
    "# Plot the model\n",
    "import graphing\n",
    "graphing.scatter_2D(test, trendline=model.predict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestra línea roja es nuestro modelo y nuestros puntos azules son nuestros puntos de datos. En el eje y, 0 significa árbol y 1 significa caminante. Podemos ver que nuestro modelo perfecto pasa por cada punto.\n",
    "\n",
    "Ahora queremos hacer una curva ROC para este modelo perfecto. Hay formas automatizadas de hacer esto, ¡pero estamos aquí para aprender! No es tan difícil de hacer nosotros mismos. Solo tenemos que dividirlo en pasos.\n",
    "\n",
    "Recuerde que una curva ROC representa la tasa de verdaderos positivos (TPR) frente a la tasa de falsos positivos (FPR). Hagamos una función que pueda calcularlos por nosotros. Si no sabe lo que significan estos términos, preste atención a los comentarios del código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tpr_fpr(prediction, actual):\n",
    "    '''\n",
    "    Calculates true positive rate and false positive rate\n",
    "\n",
    "    prediction: the labels predicted by the model\n",
    "    actual:     the correct labels we hope the model predicts\n",
    "    '''\n",
    "\n",
    "    # To calculate the true positive rate and true negative rate we need to know\n",
    "    # TP - how many true positives (where the model predicts hiker, and it is a hiker)\n",
    "    # TN - how many true negatives (where the model predicts tree, and it is a tree)\n",
    "    # FP - how many false positives (where the model predicts hiker, but it was a tree)\n",
    "    # FN - how many false negatives (where the model predicts tree, but it was a hiker)\n",
    "\n",
    "    # First, make a note of which predictions were 'true' and which were 'false'\n",
    "    prediction_true = numpy.equal(prediction, 1)\n",
    "    prediction_false= numpy.equal(prediction, 0)\n",
    "\n",
    "    # Now, make a note of which correct results were 'true' and which were 'false'\n",
    "    actual_true = numpy.equal(actual, 1)\n",
    "    actual_false = numpy.equal(actual, 0)\n",
    "\n",
    "    # Calculate TP, TN, FP, and FN\n",
    "    # The combination of sum and '&' counts the overlap\n",
    "    # For example, TP calculates how many 'true' predictions \n",
    "    # overlapped with 'true' labels (correct answers)\n",
    "    TP = numpy.sum(prediction_true  & actual_true)\n",
    "    TN = numpy.sum(prediction_false & actual_false)\n",
    "    FP = numpy.sum(prediction_true  & actual_false)\n",
    "    FN = numpy.sum(prediction_false & actual_true)\n",
    "\n",
    "    # Calculate the true positive rate\n",
    "    # This is the proportion of 'hiker' labels that are identified as hikers\n",
    "    tpr = TP / (TP + FN)\n",
    "\n",
    "    # Calculate the false positive rate \n",
    "    # This is the proportion of 'tree' labels that are identified as hikers\n",
    "    fpr = FP / (FP + TN)\n",
    "\n",
    "    # Return both rates\n",
    "    return tpr, fpr\n",
    "\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora recuerde que para hacer una curva ROC, calcule TPR y FPR para una amplia gama de umbrales. Luego trazamos el TPR en el eje y y el FPR en el eje x.\n",
    "\n",
    "Primero, hagamos un método corto que pueda calcular el TPR y el FPR para un solo umbral de decisión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_model(model_predict, feature_name, threshold):\n",
    "    '''\n",
    "    Calculates the true positive rate and false positive rate of the model\n",
    "    at a particular decision threshold\n",
    "\n",
    "    model_predict: the model's predict function\n",
    "    feature_name: the feature the model is expecting\n",
    "    threshold: the decision threshold to use \n",
    "    '''\n",
    "\n",
    "    # Make model predictions for every sample in the test set\n",
    "    # What we get back is a probability that the sample is a hiker\n",
    "    # For example, if we had two samples in the test set, we might\n",
    "    # get 0.45 and 0.65, meaning the model says there is a 45% chance\n",
    "    # the first sample is a hiker, and 65% chance the second is a \n",
    "    # hiker\n",
    "    probability_of_hiker = model_predict(test[feature_name])\n",
    "    \n",
    "    # See which predictions at this threshold would say hiker\n",
    "    predicted_is_hiker = probability_of_hiker > threshold\n",
    "\n",
    "    # calculate the true and false positives rates using our\n",
    "    # handy method\n",
    "    return calculate_tpr_fpr(predicted_is_hiker, test.is_hiker)\n",
    "\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos usarlo en un bucle para crear una curva ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_roc_curve(model_predict, feature=\"height\"):\n",
    "    '''\n",
    "    This function creates a ROC curve for a given model by testing it\n",
    "    on the test set for a range of decision thresholds. An ROC curve has\n",
    "    the True Positive rate on the x-axis and False Positive rate on the \n",
    "    y-axis\n",
    "\n",
    "    model_predict: The model's predict function\n",
    "    feature: The feature to provide the model's predict function\n",
    "    '''\n",
    "\n",
    "    # Calculate what the true positive and false positive rate would be if\n",
    "    # we had used different thresholds. \n",
    "\n",
    "    #  Make a list of thresholds to try\n",
    "    thresholds = numpy.linspace(0,1,101)\n",
    "\n",
    "    false_positive_rates = []\n",
    "    true_positive_rates = []\n",
    "\n",
    "    # Loop through all thresholds\n",
    "    for threshold in thresholds:\n",
    "        # calculate the true and false positives rates using our\n",
    "        # handy method\n",
    "        tpr, fpr = assess_model(model_predict, feature, threshold)\n",
    "\n",
    "        # save the results\n",
    "        true_positive_rates.append(tpr)\n",
    "        false_positive_rates.append(fpr)\n",
    "\n",
    "\n",
    "    # Graph the result\n",
    "    # You don't need to understand this code, but essentially we are plotting\n",
    "    # TPR versus FPR as a line plot\n",
    "    # -- Prepare a dataframe, required by our graphing code\n",
    "    df_for_graphing = pandas.DataFrame(dict(fpr=false_positive_rates, tpr=true_positive_rates, threshold=thresholds))\n",
    "    # -- Generate the plot\n",
    "    fig = graphing.scatter_2D(df_for_graphing, x_range=[-0.05,1.05])\n",
    "    fig.update_traces(mode='lines') # Comment our this line if you would like to see points rather than lines\n",
    "    fig.update_yaxes(range=[-0.05, 1.05])\n",
    "\n",
    "    # Display the graph\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Create an roc curve for our model\n",
    "create_roc_curve(model.predict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué estamos viendo aquí?\n",
    "\n",
    "Excepto en un umbral de 0, el modelo siempre tiene una tasa de verdaderos positivos de 1. También tiene siempre una tasa de falsos positivos de 0, a menos que el umbral se haya establecido en 1. Tenga en cuenta que debido a que hemos dibujado una línea, Parece que hay valores intermedios (como un FPR de 0,5) pero la línea simplemente engaña. Si lo desea, comente fig.update_traces(mode='lines') en la celda anterior y vuelva a ejecutar para ver puntos, en lugar de líneas.\n",
    "\n",
    "Piénselo: nuestro modelo es perfecto. Usándolo, siempre obtendremos todas las respuestas correctas, colocando todos los puntos en la esquina superior izquierda (a menos que el umbral sea 0 o 1, lo que significa que estamos descartando los resultados del modelo por completo).\n",
    "\n",
    "peor que el azar\n",
    "Como contraejemplo para entender la curva ROC, consideremos un modelo que es peor que el azar. De hecho, este modelo obtiene todas las respuestas incorrectas.\n",
    "\n",
    "Esto no sucede a menudo en el mundo real, por lo que nuevamente tendremos que falsificar este modelo también. Tracemos este modelo falso contra nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fake model that gets every single answer incorrect\n",
    "class VeryBadModel:\n",
    "    def predict(self, x):\n",
    "        # This model thinks that all people are over 4m tall \n",
    "        # and all trees are shorter\n",
    "        return 1 / (1 + numpy.exp(-80*(x - 4)))\n",
    "\n",
    "model = VeryBadModel()\n",
    "\n",
    "# Plot the model\n",
    "graphing.scatter_2D(test, trendline=model.predict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede ver, ¡la línea roja (modelo) va en la dirección equivocada! ¿Cómo se verá esto en una curva ROC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run our code to create the ROC curve\n",
    "create_roc_curve(model.predict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es lo opuesto al modelo perfecto. En lugar de que la línea llegue a la parte superior izquierda del gráfico, llega a la parte inferior derecha. Esto significa que el TPR siempre es 0, no hace nada bien. En este ejemplo particular, también tiene siempre una tasa de falsos positivos de 1, siempre que el umbral sea inferior a 1.\n",
    "\n",
    "Un modelo no mejor que el azar\n",
    "\n",
    "Los dos modelos anteriores que hemos visto son muy inusuales. Sin embargo, hemos aprendido que nos gustaría que la curva estuviera lo más cerca posible de la parte superior izquierda del gráfico.\n",
    "\n",
    "¿Cómo sería un modelo que no hace nada mejor que el azar? Echemos un vistazo tratando de ajustar un modelo a nuestra función de textura. Sabemos que esto no funcionará bien, porque hemos visto que los excursionistas y los árboles tienen el mismo rango de texturas de imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api\n",
    "\n",
    "# This is a helper method that reformats the data to be compatible\n",
    "# with this particular logistic regression model \n",
    "prep_data = lambda x:  numpy.column_stack((numpy.full(x.shape, 1), x))\n",
    "\n",
    "# Train a logistic regression model to predict hiker based on texture\n",
    "model = statsmodels.api.Logit(train.is_hiker, prep_data(train.texture)).fit()\n",
    "\n",
    "# Plot the model\n",
    "graphing.scatter_2D(test, label_x=\"texture\", label_y=\"is_hiker\", trendline=lambda x: model.predict(prep_data(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo no es muy bueno: no pasa por un solo punto de datos y probablemente no funcionará mejor que el azar. Esto parece extremo, pero cuando trabajamos con problemas más complicados, a veces puede ser difícil encontrar un patrón real en los datos. ¿Cómo se ve esto en una curva ROC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run our code to create the ROC curve\n",
    "create_roc_curve(lambda x: model.predict(prep_data(x)), \"texture\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Es una línea diagonal! ¿Por qué?\n",
    "\n",
    "Recuerde que el modelo no pudo encontrar una manera de predecir de manera confiable la etiqueta de la característica. Está haciendo una variedad de predicciones, pero son esencialmente conjeturas.\n",
    "\n",
    "Si tenemos un umbral de 0,5, aproximadamente la mitad de nuestras probabilidades estarán por encima del umbral, lo que significa que aproximadamente la mitad de nuestras predicciones son excursionistas. La mitad de las etiquetas también son senderistas, pero no hay correlación entre las dos. Esto significa que obtendremos aproximadamente la mitad de las etiquetas de excursionistas correctas (TPR = 0.5). También obtendremos aproximadamente la mitad de las etiquetas de excursionistas predichas incorrectas (FPR = 0.5).\n",
    "\n",
    "Si aumentáramos el umbral a 0,8, predeciría el excursionista el 80 % de las veces. Nuevamente, debido a que esto es aleatorio, identificaría aproximadamente al 80% de los excursionistas correctamente (por casualidad), y también al 80% de los árboles como excursionistas.\n",
    "\n",
    "Si continuamos con este enfoque para todos los umbrales, lograríamos una línea diagonal.\n",
    "\n",
    "Un modelo realista\n",
    "En el mundo real, por lo general logramos modelos que funcionan entre pura casualidad (una línea diagonal) y perfectamente (una línea que toca la esquina superior izquierda).\n",
    "\n",
    "Construyamos finalmente un modelo más realista. Intentaremos predecir si una muestra es un caminante o no basándonos en el movimiento. Nuestro modelo debería funcionar bien, pero no será perfecto. Esto se debe a que los excursionistas a veces se sientan quietos (como los árboles) y los árboles a veces soplan con el viento (en movimiento, como un excursionista)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api\n",
    "\n",
    "# Train a logistic regression model to predict hiker based on motion\n",
    "model = statsmodels.api.Logit(train.is_hiker, prep_data(train.motion), add_constant=True).fit()\n",
    "\n",
    "# Plot the model\n",
    "graphing.scatter_2D(test, label_x=\"motion\", label_y=\"is_hiker\", trendline=lambda x: model.predict(prep_data(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo (línea roja) parece sensato, aunque sabemos que a veces obtendrá respuestas incorrectas.\n",
    "\n",
    "Ahora veamos la curva ROC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_roc_curve(lambda x: model.predict(prep_data(x)), \"motion\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que la curva se abulta hacia la esquina superior izquierda, lo que significa que funciona mucho mejor que el azar.\n",
    "\n",
    "Esta es una curva ROC bastante típica para un problema de aprendizaje automático 'fácil' como este. Los problemas más difíciles a menudo ven la línea mucho más similar a una línea diagonal.\n",
    "\n",
    "Por el contrario, si alguna vez nos encontramos con una línea que sobresalga en la dirección opuesta, hacia abajo a la derecha, sabríamos que lo estamos haciendo peor que el azar, y que algo anda muy mal.\n",
    "\n",
    "Resumen\n",
    "¡Lo superamos! Las curvas ROC pueden parecer difíciles al principio, especialmente debido a la terminología con respecto a los positivos verdaderos y falsos. Sin embargo, construimos uno desde cero, aquí para tener una idea de cómo funcionan por dentro. Si le resultó difícil, lea de nuevo lentamente y experimente con algunas de las funciones que creamos. No se preocupe, normalmente podemos usar las bibliotecas existentes para hacer la mayor parte de este trabajo por nosotros.\n",
    "\n",
    "La moda que es importante recordar con estas curvas es que nos gustaría que nuestra línea estuviera lo más cerca posible de la parte superior izquierda del gráfico. Un modelo que puede hacer esto es identificar correctamente el objetivo (como los excursionistas) la mayor parte del tiempo, sin identificar falsamente el objetivo (etiquetar árboles como excursionistas) muy a menudo."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
