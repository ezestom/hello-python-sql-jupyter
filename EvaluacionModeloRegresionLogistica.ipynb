{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio: evaluación de un modelo de regresión logística\n",
    "\n",
    "En el ejercicio anterior, ajustamos un modelo de regresión logística simple para predecir la posibilidad de una avalancha. Esta vez, crearemos el mismo modelo y analizaremos más a fondo cómo comprender mejor los errores que comete.\n",
    "\n",
    "Visualización de datos\n",
    "Recordemos nuestros datos. Recuerde que estamos planeando entrenar un modelo que pueda predecir avalanchas en función de la cantidad de capas débiles de nieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "!pip install statsmodels\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/avalanche.csv\n",
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "\n",
    "#Import the data from the .csv file\n",
    "dataset = pandas.read_csv('avalanche.csv', delimiter=\"\\t\")\n",
    "\n",
    "#Let's have a look at the data and the relationship we're going to model\n",
    "print(dataset.head())\n",
    "\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"weak_layers\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que las avalanchas están asociadas a tener capas de nieve más débiles. Dicho esto, algunos días se registraron muchas capas débiles, pero no se produjo ninguna avalancha. Esto significa que nuestro modelo tendrá dificultades para ser extremadamente preciso usando solo esta función. Sin embargo, continuemos y volvamos a esto en un ejercicio futuro.\n",
    "\n",
    "Antes de comenzar, debemos dividir nuestro conjunto de datos en conjuntos de entrenamiento y de prueba. Entrenaremos en el conjunto de entrenamiento y probaremos (lo adivinaste) en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset in an 75/25 train/test ratio. \n",
    "train, test = train_test_split(dataset, test_size=0.25, random_state=10)\n",
    "\n",
    "print(\"Train size:\", train.shape[0])\n",
    "print(\"Test size:\", test.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste de un modelo\n",
    "\n",
    "Ajustemos un modelo de regresión logística simple utilizando log-loss como una función de costo. Esta es una forma muy estándar de ajustar un modelo de clasificación, tan estándar que, de hecho, no necesitamos especificarlo en absoluto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Perform logistic regression.\n",
    "model = smf.logit(\"avalanche ~ weak_layers\", train).fit()\n",
    "\n",
    "print(\"Model trained\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación del modelo con información resumida\n",
    "Si usamos statsmodels, podemos obtener un resumen detallado sobre el modelo simplemente llamando a summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este resumen proporciona información detallada.\n",
    "\n",
    "En la fila inferior hay dos datos útiles. El coeficiente para las capas_débiles es positivo, lo que significa que a medida que aumentan las capas_débiles, también aumenta la probabilidad de una avalancha. La columna del valor P es inferior a 0,05, lo que significa que el modelo confía en que las capas débiles son un predictor útil de avalanchas.\n",
    "\n",
    "Sin embargo, el resto de esta tabla es difícil de entender para los principiantes, por lo que no está claro qué tan bien está funcionando nuestro modelo. Probemos de otra manera.\n",
    "\n",
    "Evaluación del modelo visualmente\n",
    "A veces, pero no siempre, podemos evaluar visualmente un modo de regresión logística. Tracemos nuestro modelo contra los datos reales en el conjunto de datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(weak_layers):\n",
    "    return model.predict(dict(weak_layers=weak_layers))\n",
    "\n",
    "graphing.scatter_2D(test, label_x=\"weak_layers\", label_y=\"avalanche\", trendline=predict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es difícil ver la forma de S de la línea de tendencia, porque la cantidad de capas débiles de nieve y la probabilidad de una avalancha solo están débilmente relacionadas. Si alejamos, podemos obtener una vista ligeramente mejor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphing.scatter_2D(test, label_x=\"weak_layers\", label_y=\"avalanche\", x_range=[-20,20], trendline=predict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al revisar el gráfico anterior, podemos ver que nuestro modelo predecirá una avalancha cuando el número de capas débiles de nieve sea mayor a 5. Podemos decir esto porque el valor de la línea es 0.5 en x=5 (recuerde que en el anterior unidad definimos un umbral clasificador, de modo que las probabilidades superiores a 0,5 se clasificarían como verdaderas).\n",
    "\n",
    "Es difícil saber cómo se relaciona esto con los puntos: los puntos se superponen y, por lo tanto, es difícil ver cuántos puntos están en 0 o en 1. ¿De qué otra manera podemos evaluar el modelo?\n",
    "\n",
    "Evaluar con función de costo\n",
    "Evaluemos nuestro modelo con una función de costo de pérdida logarítmica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Make predictions from the test set\n",
    "predictions = model.predict(test)\n",
    "\n",
    "# Calculate log loss\n",
    "print(\"Log loss\", log_loss(test.avalanche, predictions))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.66 - ¿Qué significa eso? Esto podría ser útil para comparar dos modelos diferentes, pero es difícil comprender exactamente lo que esto significa para el rendimiento en el mundo real.\n",
    "\n",
    "Evaluar la precisión\n",
    "En su lugar, evalúemos la precisión. La precisión se refiere a la proporción de predicciones que el modelo acertó, después de convertir las predicciones de probabilidades a avalancha o no avalancha.\n",
    "\n",
    "Lo primero que debe hacer es convertir las probabilidades en predicciones duras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "# Print a few predictions before we convert them to categories\n",
    "print(f\"First three predictions (probabilities): {predictions.iloc[0]}, {predictions.iloc[1]}, {predictions.iloc[2]}\")\n",
    "\n",
    "# convert to absolute values\n",
    "avalanche_predicted = predictions >= 0.5\n",
    "\n",
    "# Print a few predictions converted into categories\n",
    "print(f\"First three predictions (categories): {avalanche_predicted.iloc[0]}, {avalanche_predicted.iloc[1]}, {avalanche_predicted.iloc[2]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos calcular la precisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate what proportion were predicted correctly\n",
    "guess_was_correct = test.avalanche == avalanche_predicted\n",
    "accuracy = numpy.average(guess_was_correct)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy for whole test dataset:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que está prediciendo la respuesta correcta el 61% de las veces. Esta es información útil. Sin embargo, ¿qué tipo de errores está cometiendo? Echemos un vistazo a si se trata de adivinar una avalancha cuando no la hay (falsos positivos) o no adivinar 'avalancha' cuando en realidad ocurre una (falso negativo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Negative: calculate how often it guessed no avalanche when one actually occurred\n",
    "false_negative = numpy.average(numpy.logical_not(guess_was_correct) & test.avalanche)\n",
    "\n",
    "# False positive: calculate how often it guessed avalanche, when none actually happened\n",
    "false_positive = numpy.average(numpy.logical_not(guess_was_correct) & numpy.logical_not(test.avalanche))\n",
    "\n",
    "\n",
    "print(f\"Wrongly predicted an avalanche {false_positive * 100}% of the time\")\n",
    "print(f\"Failed to predict avalanches {false_negative * 100}% of the time\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Creo que podemos estar de acuerdo en que es mucho más comprensible que la función de costo o el gráfico!\n",
    "\n",
    "Resumen\n",
    "\n",
    "Hemos repasado diferentes formas de evaluar un modelo de regresión logística. Hemos visto que los resúmenes detallados pueden proporcionar información valiosa, pero esto puede ser difícil de digerir. Las métricas para este tipo de modelos tampoco son necesariamente lo suficientemente intuitivas o detalladas para comprender el modelo. Con un poco de trabajo adicional, podemos comparar las predicciones reales con los resultados reales y obtener una intuición de cómo podría funcionar el modelo en el mundo real."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
