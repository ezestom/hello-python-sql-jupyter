{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conjuntos de prueba en profundidad\n",
    "\n",
    "En el ejercicio anterior vimos cómo dividir nuestros datos en conjuntos de entrenamiento y de prueba para evaluar el rendimiento del modelo.\n",
    "\n",
    "Ahora repetiremos el último ejercicio, pero esta vez veremos qué ocurre cuando dividimos los datos de diferentes formas y proporciones.\n",
    "\n",
    "Primero recordemos qué hay en nuestro conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "!pip install statsmodels\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/dog-training.csv\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/dog-training-switzerland.csv\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "import graphing\n",
    "\n",
    "data = pandas.read_csv(\"dog-training.csv\", delimiter=\"\\t\")\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos una rápida recapitulación de cómo es la distribución de nuestros datos (recordemos que estábamos utilizando peso_último_año para predecir el valor de rescates_último_año)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the label and feature from the original data\n",
    "dataset = data[['rescues_last_year','weight_last_year']]\n",
    "\n",
    "# Print the number of observations\n",
    "print(\"No. observations:\", dataset.shape[0])\n",
    "\n",
    "# Graph the distribution of variables for the unsplit dataset\n",
    "graphing.scatter_2D(dataset, 'rescues_last_year', 'weight_last_year')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que se han representado 50 observaciones (que corresponden al número de muestras del conjunto de datos).\n",
    "\n",
    "Comparación de la proporción de división del conjunto de datos\n",
    "Ahora vamos a dividir nuestro conjunto de datos utilizando diferentes ratios para entender cómo pueden afectar a nuestros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split Dataset using different ratios 50:50, 60:40, 70:30, 80:20\n",
    "train_5050, test_5050 = train_test_split(dataset, test_size=0.5, random_state=2)\n",
    "train_6040, test_6040 = train_test_split(dataset, test_size=0.4, random_state=2)\n",
    "train_7030, test_7030 = train_test_split(dataset, test_size=0.3, random_state=2)\n",
    "train_8020, test_8020 = train_test_split(dataset, test_size=0.2, random_state=2)\n",
    "\n",
    "# Add a column to each set to identify if a datapoint belongs to \"train\" or \"test\"\n",
    "train_5050, test_5050 = train_5050.assign(Set=\"train\"), test_5050.assign(Set=\"test\")\n",
    "train_6040, test_6040 = train_6040.assign(Set=\"train\"), test_6040.assign(Set=\"test\")\n",
    "train_7030, test_7030 = train_7030.assign(Set=\"train\"), test_7030.assign(Set=\"test\")\n",
    "train_8020, test_8020 = train_8020.assign(Set=\"train\"), test_8020.assign(Set=\"test\")\n",
    "\n",
    "# Concatenate the \"train\" and \"test\" sets for each split so we can plot them on the same chart\n",
    "df_5050 = pandas.concat([train_5050, test_5050], axis=0)\n",
    "df_6040 = pandas.concat([train_6040, test_6040], axis=0)\n",
    "df_7030 = pandas.concat([train_7030, test_7030], axis=0)\n",
    "df_8020 = pandas.concat([train_8020, test_8020], axis=0)\n",
    "\n",
    "# Plot each distribution for comparison\n",
    "graphing.scatter_2D(df_5050, \"weight_last_year\", \"rescues_last_year\", title=\"50:50 split\", label_colour=\"Set\", show=True)\n",
    "graphing.scatter_2D(df_6040, \"weight_last_year\", \"rescues_last_year\", title=\"60:40 split\", label_colour=\"Set\", show=True)\n",
    "graphing.scatter_2D(df_7030, \"weight_last_year\", \"rescues_last_year\", title=\"70:30 split\", label_colour=\"Set\", show=True)\n",
    "graphing.scatter_2D(df_8020, \"weight_last_year\", \"rescues_last_year\", title=\"80:20 split\", label_colour=\"Set\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe cómo las primeras divisiones nos dejan conjuntos de datos de entrenamiento relativamente pequeños. En la división 50:50, sólo tenemos 25 muestras para entrenar.\n",
    "\n",
    "Por otro lado, las últimas nos dejan muchos más datos para el entrenamiento, pero relativamente pocos para las pruebas. La división 80:20 nos deja sólo 10 muestras en el conjunto de prueba.\n",
    "\n",
    "Veamos las distribuciones de los datos de entrenamiento para cada división:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for each \"train\" set that identifies the split used\n",
    "train_8020 = train_8020.assign(Split=\"80:20\")\n",
    "train_7030 = train_7030.assign(Split=\"70:30\")\n",
    "train_6040 = train_6040.assign(Split=\"60:40\")\n",
    "train_5050 = train_5050.assign(Split=\"50:50\")\n",
    "\n",
    "# Concatenate training sets so we can plot them on the same chart\n",
    "split_df = pandas.concat([train_5050, train_6040, train_7030, train_8020], axis=0)\n",
    "\n",
    " # Plot a histogram of data distribution\n",
    "graphing.multiple_histogram(split_df, label_x=\"rescues_last_year\", label_group=\"Split\", title=\"Distribution of Training data\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos sacar un par de conclusiones del gráfico anterior:\n",
    "\n",
    "La función train_test_split() que utilizamos hace un trabajo bastante bueno a la hora de mantener una distribución justa de los datos entre las diferentes proporciones. Intenta mantener los diferentes valores representados en la misma proporción.\n",
    "\n",
    "Sin embargo, cuando utilizamos una proporción 50:50, ¡tenemos que dejar tantos datos fuera del conjunto de entrenamiento que algunos valores ya no están presentes! (¿puedes detectar dónde faltan barras azules?)\n",
    "\n",
    "El punto 2 es especialmente preocupante, ya que si esos datos no están disponibles para el entrenamiento, nuestro modelo no puede aprender de ellos y, por tanto, no hará predicciones precisas. En otras palabras, ¡utilizar una división 50:50 no parece una buena idea para este conjunto de datos!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste y evaluación de modelos con diferentes proporciones de división\n",
    "Vamos a ajustar modelos con diferentes proporciones de división y a ver cómo funcionan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "def train_and_test_model(name, train, test):\n",
    "    '''\n",
    "    This method creates a model, trains it on the provided data, and assesses \n",
    "    it against the test data\n",
    "    '''\n",
    "    # This formula says that rescues_last_year is explained by weight_last_year\n",
    "    formula = \"rescues_last_year ~ weight_last_year\"\n",
    "\n",
    "    # Create and train a linear regression model using the training data\n",
    "    model = smf.ols(formula = formula, data = train).fit()\n",
    "\n",
    "    # Now evaluate the model (by calculating the Mean Squared Error) using the \n",
    "    # corresponding \"test\" set for that split\n",
    "    correct_answers = test['rescues_last_year']\n",
    "    predictions = model.predict(test['weight_last_year'])\n",
    "    MSE = mse(correct_answers, predictions)\n",
    "    print(name + ' MSE = %f ' % MSE)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Train a model and test it for each kind of split\n",
    "print(\"Mean Squared Error values (smaller is better)\")\n",
    "model_5050 = train_and_test_model(\"50:50\", train_5050, test_5050)\n",
    "model_6040 = train_and_test_model(\"60:40\", train_6040, test_6040)\n",
    "model_7030 = train_and_test_model(\"70:30\", train_7030, test_7030)\n",
    "model_8020 = train_and_test_model(\"80:20\", train_8020, test_8020)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior entrena un modelo para cada relación, utilizando el conjunto de entrenamiento correspondiente a esa relación. A continuación, calcula el MSE (error cuadrático medio) de cada modelo utilizando el conjunto de prueba correspondiente.\n",
    "\n",
    "Los resultados parecen variados. La proporción 80:20 fue la mejor, pero no hay una pauta clara sobre si resulta útil aumentar o reducir el conjunto de entrenamiento.\n",
    "\n",
    "Hay dos factores que influyen en los resultados. En primer lugar, cuanto mayor sea el conjunto de pruebas, más podemos confiar en los resultados de las pruebas. En segundo lugar, los modelos suelen entrenarse mejor con conjuntos de entrenamiento más grandes.\n",
    "\n",
    "Estas influencias son contradictorias entre sí, y su influencia se ve exagerada en este caso porque nuestro conjunto de datos es muy pequeño. En esta situación concreta es difícil evaluar si la división 60:40 es realmente mejor que la 70:30, por ejemplo. Esto se debe a que la división 70:30 podría parecer peor porque se probó con un conjunto de pruebas menos representativo (más pequeño).\n",
    "\n",
    "Evaluación del modelo\n",
    "Veamos ahora qué ocurre cuando estos modelos se utilizan con un conjunto de datos mucho mayor en el que no se han entrenado ni probado. Esto puede ocurrir en el mundo real porque decidimos retener datos al principio, o simplemente porque recopilamos datos después de entrenar nuestro modelo. En nuestro caso, se trata de nuevos datos que nos ha proporcionado la sección europea de nuestra organización benéfica de rescate en avalanchas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "# Load some dog statistics from our charity's European arm\n",
    "swiss_data = pandas.read_csv(\"dog-training-switzerland.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Show show information about the data\n",
    "print(f\"The Swiss dataset contains {swiss_data.shape[0]} samples\")\n",
    "graphing.scatter_2D(swiss_data, 'rescues_last_year', 'weight_last_year')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se trata claramente de una muestra de datos mucho mayor. Veamos cómo funcionan nuestros modelos. Ten en cuenta que aquí no estamos volviendo a entrenar los modelos; simplemente los estamos utilizando para hacer predicciones en un nuevo conjunto de datos para evaluar su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test our models against the swiss data\n",
    "features = swiss_data['weight_last_year']\n",
    "correct_answers = swiss_data['rescues_last_year']\n",
    "\n",
    "# We will now assess our models. Notice we're not training them again.\n",
    "# We are simply testing them against some new data \n",
    "\n",
    "# Assess the model trained on a 50:50 split\n",
    "predictions = model_5050.predict(features)\n",
    "MSE = mse(correct_answers, predictions)\n",
    "print('50:50 MSE = %f ' % MSE)\n",
    "\n",
    "# Assess the model trained on a 60:40 split\n",
    "predictions = model_6040.predict(features)\n",
    "MSE = mse(correct_answers, predictions)\n",
    "print('60:40 MSE = %f ' % MSE)\n",
    "\n",
    "# Assess the model trained on a 70:30 split\n",
    "predictions = model_7030.predict(features)\n",
    "MSE = mse(correct_answers, predictions)\n",
    "print('70:30 MSE = %f ' % MSE)\n",
    "\n",
    "# Assess the model trained on a 80:20 split\n",
    "predictions = model_8020.predict(features)\n",
    "MSE = mse(correct_answers, predictions)\n",
    "print('80:20 MSE = %f ' % MSE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este conjunto de datos más amplio, el modelo que utilizó la división 80:20 arrojó el error más bajo y, por tanto, el mejor rendimiento. También se observa un patrón claro: cuanto mayor es el conjunto de datos de entrenamiento, mejor es el rendimiento del modelo tras el entrenamiento.\n",
    "\n",
    "En conjunto, esto demuestra que deberíamos probar y evaluar diferentes divisiones de entrenamiento/prueba al construir modelos de aprendizaje automático, y que generalmente las divisiones que favorecen el conjunto de entrenamiento con más datos producirán mejores resultados.\n",
    "\n",
    "Resumen\n",
    "En este ejercicio has aprendido los siguientes conceptos:\n",
    "\n",
    "Puede utilizar diferentes proporciones al dividir su conjunto de datos en conjuntos de entrenamiento y prueba.<br>\n",
    "Diferentes proporciones producen diferentes distribuciones de variables en los conjuntos de entrenamiento y prueba resultantes.<br>\n",
    "Cuando las proporciones de entrenamiento:prueba son cercanas, es posible que esté dejando muchos datos fuera del conjunto de entrenamiento, lo que puede tener un impacto negativo en el rendimiento del modelo.<br>\n",
    "Cuando se construyen modelos, es importante probarlos utilizando diferentes combinaciones de entrenamiento/prueba. Asignar simplemente más datos al conjunto de entrenamiento no siempre garantiza los mejores resultados."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
