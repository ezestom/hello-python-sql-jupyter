{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conjuntos de entrenamiento y prueba<br>\n",
    "Ya hemos visto cómo ajustar un modelo a un conjunto de datos. En este ejercicio, veremos cómo comprobar y confirmar la validez y el rendimiento de nuestros modelos utilizando conjuntos de entrenamiento y de prueba. Como de costumbre, empezamos por cargar y echar un vistazo a nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "!pip install statsmodels\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/dog-training.csv\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/dog-training-switzerland.csv\n",
    "\n",
    "data = pandas.read_csv(\"dog-training.csv\", delimiter=\"\\t\")\n",
    "\n",
    "print(data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos interesa la relación entre el peso de un perro y la cantidad de rescates que realizó el año anterior. Empecemos trazando rescates_último_año en función de peso_último_año:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphing\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# First, we define our formula using a special syntax\n",
    "# This says that rescues_last_year is explained by weight_last_year\n",
    "formula = \"rescues_last_year ~ weight_last_year\"\n",
    "\n",
    "model = smf.ols(formula = formula, data = data).fit()\n",
    "\n",
    "graphing.scatter_2D(data, \"weight_last_year\", \"rescues_last_year\", trendline = lambda x: model.params[1] * x + model.params[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece haber una relación bastante clara entre el peso de un perro y el número de rescates que ha realizado. Esto parece bastante razonable, ya que cabría esperar que los perros más pesados fueran más grandes y fuertes y, por tanto, mejores salvando vidas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partición de entrenamiento/prueba<br>\n",
    "Esta vez, en lugar de ajustar un modelo a la totalidad de nuestro conjunto de datos, vamos a separar nuestro conjunto de datos en dos particiones más pequeñas: un conjunto de entrenamiento y un conjunto de prueba.\n",
    "El conjunto de entrenamiento es el más grande de los dos, y suele estar formado por entre el 70 y el 80% del conjunto de datos, mientras que el resto constituye el conjunto de prueba. Al dividir los datos, podemos medir el rendimiento de nuestro modelo cuando se enfrenta a datos que no se han visto antes.\n",
    "\n",
    "Tenga en cuenta que los datos del conjunto de prueba nunca se utilizan en el entrenamiento. Por eso se suelen denominar datos no vistos o datos desconocidos por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Obtain the label and feature from the original data\n",
    "dataset = data[['rescues_last_year','weight_last_year']]\n",
    "\n",
    "# Split the dataset in an 70/30 train/test ratio. We also obtain the respective corresponding indices from the original dataset.\n",
    "train, test = train_test_split(dataset, train_size=0.7, random_state=21)\n",
    "\n",
    "print(\"Train\")\n",
    "print(train.head())\n",
    "print(train.shape)\n",
    "\n",
    "print(\"Test\")\n",
    "print(test.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que estos conjuntos son diferentes, y que el conjunto de entrenamiento y el conjunto de prueba contienen el 70% y el 30% de los datos totales, respectivamente.\n",
    "\n",
    "Veamos cómo se separan el conjunto de entrenamiento y el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't need to understand this code well\n",
    "# It's just used to create a scatter plot\n",
    "\n",
    "# concatenate training and test so they can be graphed\n",
    "plot_set = pandas.concat([train,test])\n",
    "plot_set[\"Dataset\"] = [\"train\"] * len(train) + [\"test\"] * len(test)\n",
    "\n",
    "# Create graph\n",
    "graphing.scatter_2D(plot_set, \"weight_last_year\", \"rescues_last_year\", \"Dataset\", trendline = lambda x: model.params[1] * x + model.params[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conjunto de entrenamiento<br>\n",
    "Comenzamos entrenando nuestro modelo utilizando el conjunto de entrenamiento y probamos su rendimiento con el mismo conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "# First, we define our formula using a special syntax\n",
    "# This says that rescues_last_year is explained by weight_last_year\n",
    "formula = \"rescues_last_year ~ weight_last_year\"\n",
    "\n",
    "# Create and train the model\n",
    "model = smf.ols(formula = formula, data = train).fit()\n",
    "\n",
    "# Graph the result against the data\n",
    "graphing.scatter_2D(train, \"weight_last_year\", \"rescues_last_year\", trendline = lambda x: model.params[1] * x + model.params[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos medir el rendimiento de nuestro modelo calculando el error cuadrático medio (ECM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the in-buit sklearn function to calculate the MSE\n",
    "correct_labels = train['rescues_last_year']\n",
    "predicted = model.predict(train['weight_last_year'])\n",
    "\n",
    "MSE = mse(correct_labels, predicted)\n",
    "print('MSE = %f ' % MSE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conjunto de pruebas\n",
    "A continuación, probamos el rendimiento del mismo modelo utilizando el conjunto de pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphing.scatter_2D(test, \"weight_last_year\", \"rescues_last_year\", trendline = lambda x: model.params[1] * x + model.params[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Echemos un vistazo de nuevo al MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_labels = test['rescues_last_year']\n",
    "predicted = model.predict(test['weight_last_year'])\n",
    "\n",
    "MSE = mse(correct_labels, predicted)\n",
    "print('MSE = %f ' % MSE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que el modelo funciona mucho mejor con los datos de entrenamiento conocidos que con los datos de prueba desconocidos (recuerde que los valores de MSE más altos son peores).\n",
    "\n",
    "Esto puede deberse a varios factores, pero el primero y más importante es el sobreajuste, que se produce cuando un modelo se ajusta demasiado a los datos del conjunto de entrenamiento. Esto significa que funcionará muy bien en el conjunto de entrenamiento, pero no generalizará bien. (es decir, no funcionará bien con otros conjuntos de datos)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevo conjunto de datos<br>\n",
    "Para ilustrar mejor nuestra idea, veamos cómo se comporta nuestro modelo ante un conjunto de datos completamente nuevo, desconocido y de mayor tamaño. Para nuestro escenario, utilizaremos los datos proporcionados por la rama europea de la organización benéfica de rescate en avalanchas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an alternative dataset from the charity's European branch\n",
    "new_data = pandas.read_csv(\"dog-training-switzerland.csv\", delimiter=\"\\t\")\n",
    "\n",
    "print(new_data.shape)\n",
    "new_data.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las características son las mismas, pero esta vez tenemos muchos más datos. Veamos cómo funciona nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fitted model against this new dataset. \n",
    "\n",
    "graphing.scatter_2D(new_data, \"weight_last_year\", \"rescues_last_year\", trendline = lambda x: model.params[1] * x + model.params[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora el MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_labels = new_data['rescues_last_year']\n",
    "predicted = model.predict(new_data['weight_last_year'])\n",
    "\n",
    "MSE = mse(correct_labels, predicted)\n",
    "print('MSE = %f ' % MSE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era de esperar, el modelo funciona mejor en el conjunto de datos de entrenamiento que en el conjunto de datos no visto. Esto se debe simplemente al sobreajuste, como vimos anteriormente.\n",
    "\n",
    "Curiosamente, el modelo funciona mejor en este conjunto de datos que en el de prueba. Esto se debe a que nuestro conjunto de pruebas anterior era bastante pequeño y, por tanto, no representaba muy bien los datos del \"mundo real\". En cambio, este conjunto de datos es grande y representa mucho mejor los datos que encontraremos fuera del laboratorio. En esencia, esto nos muestra que parte de la diferencia de rendimiento que vemos entre el entrenamiento y la prueba se debe al sobreajuste del modelo, y parte del error se debe a que el conjunto de prueba no es perfecto. En los próximos ejercicios, exploraremos el equilibrio que tenemos que hacer entre los tamaños de los conjuntos de datos de entrenamiento y de prueba.\n",
    "\n",
    "Resumen\n",
    "\n",
    "En este ejercicio hemos tratado los siguientes conceptos\n",
    "\n",
    "Dividir un conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba.<br>\n",
    "Entrenamiento de un modelo utilizando el conjunto de entrenamiento y comprobación de su rendimiento en el conjunto de entrenamiento, en el conjunto de prueba y en un nuevo conjunto de datos desconocido.<br>\n",
    "Comparación de los respectivos MSE para poner de relieve los efectos y peligros del sobreajuste."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
