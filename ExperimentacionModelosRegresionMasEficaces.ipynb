{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión - Experimentación con modelos adicionales\n",
    "\n",
    "En el cuaderno anterior, utilizamos modelos de regresión simples para observar la relación entre las características de un conjunto de datos de alquiler de bicicletas. En este cuaderno, experimentaremos con modelos más complejos para mejorar el rendimiento de nuestra regresión.\n",
    "\n",
    "Empezaremos cargando los datos de alquiler de bicicletas como un Pandas DataFrame y visualizando las primeras filas. También dividiremos nuestros datos en conjuntos de datos de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules we'll need for this notebook\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load the training dataset\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/ml-basics/daily-bike-share.csv\n",
    "bike_data = pd.read_csv('daily-bike-share.csv')\n",
    "bike_data['day'] = pd.DatetimeIndex(bike_data['dteday']).day\n",
    "numeric_features = ['temp', 'atemp', 'hum', 'windspeed']\n",
    "categorical_features = ['season','mnth','holiday','weekday','workingday','weathersit', 'day']\n",
    "bike_data[numeric_features + ['rentals']].describe()\n",
    "print(bike_data.head())\n",
    "\n",
    "\n",
    "# Separate features and labels\n",
    "# After separating the dataset, we now have numpy arrays named **X** containing the features, and **y** containing the labels.\n",
    "X, y = bike_data[['season','mnth', 'holiday','weekday','workingday','weathersit','temp', 'atemp', 'hum', 'windspeed']].values, bike_data['rentals'].values\n",
    "\n",
    "# Split data 70%-30% into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "print ('Training Set: %d rows\\nTest Set: %d rows' % (X_train.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos los siguientes cuatro conjuntos de datos:\n",
    "\n",
    "X_entrenamiento: Los valores de las características que utilizaremos para entrenar el modelo<br>\n",
    "y_train: Las etiquetas correspondientes que utilizaremos para entrenar el modelo.<br>\n",
    "X_prueba: Los valores de las características que utilizaremos para validar el modelo<br>\n",
    "y_test: Las etiquetas correspondientes que utilizaremos para validar el modelo.<br>\n",
    "Ahora estamos listos para entrenar un modelo ajustando un algoritmo de regresión adecuado a los datos de entrenamiento.\n",
    "\n",
    "Experimentar con algoritmos\n",
    "\n",
    "El algoritmo de regresión lineal que utilizamos la última vez para entrenar el modelo tiene cierta capacidad predictiva, pero hay muchos tipos de algoritmo de regresión que podríamos probar, entre ellos:\n",
    "\n",
    "Algoritmos lineales: No sólo el algoritmo de regresión lineal que utilizamos anteriormente (que técnicamente es un algoritmo de mínimos cuadrados ordinarios), sino otras variantes como Lasso y Ridge.<br>\n",
    "Algoritmos basados en árboles: Algoritmos que construyen un árbol de decisión para llegar a una predicción.<br>\n",
    "Algoritmos de conjunto: Algoritmos que combinan los resultados de múltiples algoritmos base para mejorar la generalizabilidad."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebe otro algoritmo lineal\n",
    "Intentemos entrenar nuestro modelo de regresión utilizando un algoritmo Lasso. Podemos hacerlo simplemente cambiando el estimador en el código de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Fit a lasso model on the training set\n",
    "model = Lasso().fit(X_train, y_train)\n",
    "print (model, \"\\n\")\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebe un algoritmo de árbol de decisión\n",
    "\n",
    "Como alternativa a un modelo lineal, existe una categoría de algoritmos para el aprendizaje automático que utiliza un enfoque basado en árboles en el que las características del conjunto de datos se examinan en una serie de evaluaciones, cada una de las cuales da lugar a una rama en un árbol de decisión basado en el valor de la característica. Al final de cada serie de ramas se encuentran los nodos hoja con el valor de la etiqueta predicha en función de los valores de las características.\n",
    "\n",
    "Es más fácil ver cómo funciona esto con un ejemplo. Vamos a entrenar un modelo de regresión de árbol de decisión utilizando los datos de alquiler de bicicletas. Después de entrenar el modelo, el código siguiente imprimirá la definición del modelo y una representación de texto del árbol que utiliza para predecir los valores de las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "# Train the model\n",
    "model = DecisionTreeRegressor().fit(X_train, y_train)\n",
    "print (model, \"\\n\")\n",
    "\n",
    "# Visualize the model tree\n",
    "tree = export_text(model)\n",
    "print(tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos un modelo basado en árboles, pero ¿es bueno? Evaluémoslo con los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo basado en árboles no parece haber mejorado con respecto al modelo lineal, así que ¿qué más podríamos probar?\n",
    "\n",
    "Probar un algoritmo de conjunto\n",
    "Los algoritmos de conjunto combinan varios estimadores de base para producir un modelo óptimo, ya sea aplicando una función agregada a una colección de modelos de base (lo que a veces se denomina bagging) o construyendo una secuencia de modelos que se basan unos en otros para mejorar el rendimiento predictivo (lo que se denomina boosting).\n",
    "\n",
    "Por ejemplo, probemos un modelo de Bosque Aleatorio, que aplica una función de promediado a múltiples modelos de Árbol de Decisión para obtener un modelo global mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestRegressor().fit(X_train, y_train)\n",
    "print (model, \"\\n\")\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por si fuera poco, probemos también un algoritmo de conjunto de refuerzo. Utilizaremos un estimador Gradient Boosting, que al igual que un algoritmo Random Forest construye múltiples árboles, pero en lugar de construirlos todos independientemente y tomar el resultado medio, cada árbol se construye sobre los resultados del anterior en un intento de reducir incrementalmente la pérdida (error) en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Fit a lasso model on the training set\n",
    "model = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "print (model, \"\\n\")\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(\"MSE:\", mse)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "print(\"R2:\", r2)\n",
    "\n",
    "# Plot predicted vs actual\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Labels')\n",
    "plt.ylabel('Predicted Labels')\n",
    "plt.title('Daily Bike Share Predictions')\n",
    "# overlay the regression line\n",
    "z = np.polyfit(y_test, predictions, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(y_test,p(y_test), color='magenta')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumen\n",
    "\n",
    "Aquí hemos probado una serie de nuevos algoritmos de regresión para mejorar el rendimiento. En nuestro cuaderno veremos cómo \"afinar\" estos algoritmos para mejorar el rendimiento.\n",
    "\n",
    "Lecturas adicionales\n",
    "\n",
    "Para obtener más información sobre Scikit-Learn, consulte la documentación de Scikit-Learn https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
