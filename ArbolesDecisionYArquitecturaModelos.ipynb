{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio: árboles de decisión y arquitectura modelo\n",
    "\n",
    "Nuestro objetivo en este ejercicio es utilizar un clasificador de árbol de decisiones para predecir si un delito individual se resolverá, en función de información simple como dónde tuvo lugar y qué tipo de delito fue.\n",
    "\n",
    "Visualización de datos\n",
    "Como de costumbre, comencemos cargando y echando un vistazo a nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/san_fran_crime.csv\n",
    "\n",
    "#Import the data from the .csv file\n",
    "dataset = pandas.read_csv('san_fran_crime.csv', delimiter=\"\\t\")\n",
    "\n",
    "#Let's have a look at the data and the relationship we are going to model\n",
    "print(dataset.head())\n",
    "print(dataset.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestros datos parecen ser una combinación de variables categóricas como Categoría delictiva o PdDistrict, y variables numéricas como el día_del_año (1-365) y el tiempo_en_horas (hora del día, convertida en flotante). También tenemos X e Y que se refieren a coordenadas GPS y Resolución que es nuestra etiqueta.\n",
    "\n",
    "Visualicemos nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "import numpy as np\n",
    "\n",
    "# Crime category\n",
    "graphing.multiple_histogram(dataset, label_x='Category', label_group=\"Resolution\", histfunc='sum', show=True)\n",
    "\n",
    "# District\n",
    "graphing.multiple_histogram(dataset, label_group=\"Resolution\", label_x=\"PdDistrict\", show=True)\n",
    "\n",
    "# Map of crimes\n",
    "graphing.scatter_2D(dataset, label_x=\"X\", label_y=\"Y\", label_colour=\"Resolution\", title=\"GPS Coordinates\", size_multiplier=0.8, show=True)\n",
    "\n",
    "# Day of the week\n",
    "graphing.multiple_histogram(dataset, label_group=\"Resolution\", label_x=\"DayOfWeek\", show=True)\n",
    "\n",
    "# day of the year\n",
    "# For graphing we simplify this to week or the graph becomes overwhelmed with bars\n",
    "dataset[\"week_of_year\"] = np.round(dataset.day_of_year / 7.0)\n",
    "graphing.multiple_histogram(dataset, \n",
    "                    label_x='week_of_year',\n",
    "                    label_group='Resolution',\n",
    "                    histfunc='sum', show=True)\n",
    "del dataset[\"week_of_year\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre vale la pena inspeccionar sus datos antes de sumergirse. Lo que podemos ver aquí es que:\n",
    "\n",
    "La mayoría de los delitos denunciados no se resolvieron en 2016<br>\n",
    "Diferentes distritos policiales informaron diferentes volúmenes de delincuencia.<br>\n",
    "Diferentes distritos policiales informaron diferentes tasas de éxito en la resolución de delitos.<br>\n",
    "El viernes y el sábado típicamente tenían más delitos que otros días.<br>\n",
    "Larsony/Theft fue abrumadoramente el delito más común denunciado<br>\n",
    "Finalización de la preparación de datos\n",
    "Finalicemos nuestra preparación de datos mediante la codificación one-hot de nuestras características categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical features\n",
    "dataset = pandas.get_dummies(dataset, columns=[\"Category\", \"PdDistrict\"], drop_first=False)\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También necesitamos hacer un conjunto de entrenamiento y prueba.\n",
    "\n",
    "¿Notaste con cuántos datos estábamos trabajando antes? Si no es así, vuelva a comprobar las impresiones desde arriba.\n",
    "\n",
    "Tenemos más de 150.000 muestras con las que trabajar. Esa es una gran cantidad de datos. Debido al gran tamaño, podemos darnos el lujo de tener una mayor proporción en el conjunto de entrenamiento que normalmente tendríamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset in an 90/10 train/test ratio. \n",
    "# We can afford to do this here because our dataset is very very large\n",
    "# Normally we would choose a more even ratio\n",
    "train, test = train_test_split(dataset, test_size=0.1, random_state=2, shuffle=True)\n",
    "\n",
    "print(\"Data shape:\")\n",
    "print(\"train\", train.shape)\n",
    "print(\"test\", test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código de evaluación del modelo\n",
    "Ajustaremos varios modelos aquí, por lo que para maximizar la reutilización del código, crearemos un método dedicado que entrene un modelo y luego lo pruebe.\n",
    "\n",
    "Nuestra etapa de prueba utiliza una métrica llamada \"precisión equilibrada\", a la que nos referiremos como \"precisión\" para abreviar a lo largo de este ejercicio. No es crítico que entiendas esta métrica para estos ejercicios, pero en esencia está entre 0 y 1:\n",
    "\n",
    "0 significa que ninguna respuesta fue correcta<br>\n",
    "1 significa que todas las respuestas fueron correctas<br>\n",
    "La precisión equilibrada tiene en cuenta que nuestro conjunto de datos tiene más delitos sin resolver que resueltos. Cubriremos lo que esto significa en material de aprendizaje posterior en este curso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Make a utility method that we can re-use throughout this exercise\n",
    "# To easily fit and test out model\n",
    "\n",
    "features = [c for c in dataset.columns if c != \"Resolution\"]\n",
    "\n",
    "\n",
    "def fit_and_test_model(model):\n",
    "    '''\n",
    "    Trains a model and tests it against both train and test sets\n",
    "    '''  \n",
    "    global features\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(train[features], train.Resolution)\n",
    "\n",
    "    # Assess its performance\n",
    "    # -- Train\n",
    "    predictions = model.predict(train[features])\n",
    "    train_accuracy = balanced_accuracy_score(train.Resolution, predictions)\n",
    "\n",
    "    # -- Test\n",
    "    predictions = model.predict(test[features])\n",
    "    test_accuracy = balanced_accuracy_score(test.Resolution, predictions)\n",
    "\n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "\n",
    "print(\"Ready to go!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste de un árbol de decisión\n",
    "Usemos un árbol de decisiones para ayudarnos a determinar si se resolverá un delito. Los árboles de decisión son modelos de categorización que dividen las decisiones en varios pasos. Se pueden comparar con un diagrama de flujo, en el que se toma una decisión en cada nivel subsiguiente del árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree\n",
    "\n",
    "# fit a simple tree using only three levels\n",
    "model = sklearn.tree.DecisionTreeClassifier(random_state=2, max_depth=3) \n",
    "train_accuracy, test_accuracy = fit_and_test_model(model)\n",
    "\n",
    "print(\"Model trained!\")\n",
    "print(\"Train accuracy\", train_accuracy)\n",
    "print(\"Test accuracy\", test_accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡No esta mal! Ahora que el modelo está entrenado, visualicémoslo para que podamos tener una mejor idea de cómo funciona (¡y también de dónde obtiene su nombre de árbol!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------\n",
    "from sklearn.tree import plot_tree\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plot = plt.subplots(figsize = (4,4), dpi=300)[0]\n",
    "plot = plot_tree(model,\n",
    "                fontsize=3,\n",
    "                feature_names = features, \n",
    "                class_names = ['0','1'], # class_names in ascending numerical order \n",
    "                label=\"root\",\n",
    "                impurity=False,\n",
    "                filled=True) \n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos los recuadros de color azul corresponden a la predicción de que se resolvería un delito.\n",
    "\n",
    "Eche un vistazo al árbol para ver lo que cree que es importante para predecir un resultado. Compare esto con los gráficos que hicimos anteriormente. ¿Puedes ver una relación entre los dos?\n",
    "\n",
    "La partitura que tenemos no está mal, pero el árbol es bastante sencillo. Veamos si podemos hacerlo mejor.\n",
    "\n",
    "Mejora del rendimiento a través de la arquitectura\n",
    "Intentaremos mejorar el rendimiento de nuestro modelo cambiando su arquitectura. Centrémonos en el parámetro de profundidad_máxima.\n",
    "\n",
    "Nuestro árbol anterior era relativamente simple y poco profundo con una profundidad_máxima = 3. Veamos qué sucede si lo aumentamos a 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit a very deep tree\n",
    "model = sklearn.tree.DecisionTreeClassifier(random_state=1, max_depth=100)\n",
    "\n",
    "train_accuracy, test_accuracy = fit_and_test_model(model)\n",
    "print(\"Train accuracy\", train_accuracy)\n",
    "print(\"Test accuracy\", test_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes imaginar, un árbol con una profundidad_máxima = 100 es grande. Demasiado grande para visualizarlo aquí, así que pasemos directamente a ver cómo funciona el nuevo modelo en nuestros datos de entrenamiento.\n",
    "\n",
    "Tanto el entrenamiento como la precisión de las pruebas han aumentado mucho. La formación, sin embargo, ha aumentado mucho más. Si bien estamos contentos con la mejora en la precisión de las pruebas, esta es una clara señal de sobreajuste.\n",
    "\n",
    "El sobreajuste con árboles de decisión se vuelve aún más obvio cuando tenemos conjuntos de datos de tamaño más típico (más pequeño). Volvamos a ejecutar el ejercicio anterior pero con solo 100 muestras de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily shrink the training set to something\n",
    "# more realistic\n",
    "full_training_set = train\n",
    "train = train[:100]\n",
    "\n",
    "# fit the same tree as before\n",
    "model = sklearn.tree.DecisionTreeClassifier(random_state=1, max_depth=100)\n",
    "\n",
    "# Assess on the same test set as before\n",
    "train_accuracy, test_accuracy = fit_and_test_model(model)\n",
    "print(\"Train accuracy\", train_accuracy)\n",
    "print(\"Test accuracy\", test_accuracy)\n",
    "\n",
    "# Roll the training set back to the full set\n",
    "train = full_training_set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo funciona mal en los datos de prueba. Con conjuntos de datos de tamaño razonable, los árboles de decisión son notoriamente propensos al sobreajuste. En otras palabras, tienden a adaptarse muy bien a los datos en los que están capacitados, pero generalizan muy mal a datos desconocidos. Esto empeora cuanto más profundo se vuelve el árbol o más pequeño se vuelve el conjunto de entrenamiento. A ver si podemos mitigar esto.\n",
    "\n",
    "podar un arbol\n",
    "La poda es el proceso de simplificar un árbol de decisión para que proporcione los mejores resultados de clasificación y, al mismo tiempo, reduzca el sobreajuste. Hay dos tipos de poda: prepoda y pospoda.\n",
    "\n",
    "La poda previa implica restringir el modelo durante el entrenamiento, para que no crezca más de lo útil. Cubriremos esto a continuación.\n",
    "\n",
    "La post-poda es cuando simplificamos el árbol después de entrenarlo. No implica tomar ninguna decisión de diseño antes de tiempo, sino simplemente optimizar el modelo existente. Esta es una técnica válida pero es bastante complicada, por lo que no la cubrimos aquí debido a limitaciones de tiempo.\n",
    "\n",
    "Prepoda\n",
    "Podemos realizar una poda previa generando muchos modelos, cada uno con diferentes parámetros de profundidad máxima. Para cada uno, registramos la precisión equilibrada para el conjunto de prueba. Para mostrar que esto es importante incluso con conjuntos de datos bastante grandes, aquí trabajaremos con 10000 muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily shrink the training set to 10000\n",
    "# for this exercise to see how pruning is important\n",
    "# even with moderately large datasets\n",
    "full_training_set = train\n",
    "train = train[:10000]\n",
    "\n",
    "\n",
    "# Loop through the values below and build a model\n",
    "# each time, setting the maximum depth to that value \n",
    "max_depth_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ,15, 20, 50, 100]\n",
    "accuracy_trainset = []\n",
    "accuracy_testset = []\n",
    "for depth in max_depth_range:\n",
    "    # Create and fit the model\n",
    "    prune_model = sklearn.tree.DecisionTreeClassifier(random_state=1, max_depth=depth)\n",
    "\n",
    "    # Calculate and record its sensitivity\n",
    "    train_accuracy, test_accuracy = fit_and_test_model(prune_model)\n",
    "    accuracy_trainset.append(train_accuracy)\n",
    "    accuracy_testset.append(test_accuracy)\n",
    "\n",
    "# Plot the sensitivity as a function of depth  \n",
    "pruned_plot = pandas.DataFrame(dict(max_depth=max_depth_range, accuracy=accuracy_trainset))\n",
    "\n",
    "fig = graphing.line_2D(dict(train=accuracy_trainset, test=accuracy_testset), x_range=max_depth_range, show=True)\n",
    "\n",
    "# Roll the training set back to the full thing\n",
    "train = full_training_set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver en nuestro gráfico que la mejor precisión se obtiene para una profundidad máxima de aproximadamente 10. Estamos buscando simplificar nuestro árbol, por lo que elegimos profundidad máxima = 10 para nuestro árbol podado final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily shrink the training set to 10000\n",
    "# for this exercise to see how pruning is important\n",
    "# even with moderately large datasets\n",
    "full_training_set = train\n",
    "train = train[:10000]\n",
    "\n",
    "\n",
    "# Not-pruned\n",
    "model = sklearn.tree.DecisionTreeClassifier(random_state=1)\n",
    "train_accuracy, test_accuracy = fit_and_test_model(model)\n",
    "print(\"Unpruned Train accuracy\", train_accuracy)\n",
    "print(\"Unpruned Test accuracy\", test_accuracy)\n",
    "\n",
    "\n",
    "# re-fit our final tree to print out its performance\n",
    "model = sklearn.tree.DecisionTreeClassifier(random_state=1, max_depth=10)\n",
    "train_accuracy, test_accuracy = fit_and_test_model(model)\n",
    "print(\"Train accuracy\", train_accuracy)\n",
    "print(\"Test accuracy\", test_accuracy)\n",
    "\n",
    "# Roll the training set back to the full thing\n",
    "train = full_training_set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro nuevo y mejorado modelo podado muestra una precisión equilibrada marginalmente mejor en el conjunto de prueba y un rendimiento mucho peor en el conjunto de entrenamiento que el modelo que no está podado. Esto significa que nuestra poda ha reducido significativamente el sobreajuste.\n",
    "\n",
    "Si lo desea, regrese y cambie el número de muestras a 100, y observe cómo cambia la profundidad máxima óptima. Piense por qué podría ser esto (pista: complejidad del modelo frente al tamaño de la muestra)\n",
    "\n",
    "Otra opción con la que te puede gustar jugar es cuántas funciones se ingresan en el árbol. Se pueden observar patrones similares de sobreajuste manipulando esto. De hecho, el número y el tipo de características proporcionadas a un árbol de decisión pueden ser incluso más importantes que su tamaño.\n",
    "\n",
    "Resumen\n",
    "\n",
    "En esta unidad tratamos los siguientes temas:\n",
    "\n",
    "Usar técnicas de visualización para obtener información sobre nuestros datos<br>\n",
    "Construcción de un modelo de árbol de decisión simple<br>\n",
    "Uso del modelo entrenado para predecir etiquetas<br>\n",
    "Recortar un árbol de decisiones para reducir los efectos del sobreajuste"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
