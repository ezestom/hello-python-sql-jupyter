{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejercicio: sesgo del modelo de datos desequilibrados\n",
    "\n",
    "En este ejercicio, analizaremos más de cerca los conjuntos de datos desequilibrados, qué efectos tienen en las predicciones y cómo se pueden abordar.\n",
    "\n",
    "También emplearemos matrices de confusión para evaluar las actualizaciones del modelo.\n",
    "\n",
    "Visualización de datos\n",
    "\n",
    "Al igual que en el ejercicio anterior, usamos un conjunto de datos que representa diferentes clases de objetos que se encuentran en la montaña:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/snow_objects.csv\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/snow_objects_balanced.csv\n",
    "\n",
    "#Import the data from the .csv file\n",
    "dataset = pandas.read_csv('snow_objects.csv', delimiter=\"\\t\")\n",
    "\n",
    "# Let's have a look at the data\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerde que tenemos un *conjunto de datos desequilibrado*. Algunas clases son mucho más frecuentes que otras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "\n",
    "# Plot a histogram with counts for each label\n",
    "graphing.multiple_histogram(dataset, label_x=\"label\", label_group=\"label\", title=\"Label distribution\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la clasificación binaria\n",
    "\n",
    "Para este ejercicio construiremos un modelo de clasificación binaria. Queremos predecir si los objetos en la nieve son \"excursionistas\" o \"no excursionistas\".\n",
    "\n",
    "Para hacer eso, primero debemos agregar otra columna a nuestro conjunto de datos y establecerla en True donde la etiqueta original es excursionista, y False en cualquier otra cosa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new label with true/false values to our dataset\n",
    "dataset[\"is_hiker\"] = dataset.label == \"hiker\"\n",
    "\n",
    "# Plot frequency for new label\n",
    "graphing.multiple_histogram(dataset, label_x=\"is_hiker\", label_group=\"is_hiker\", title=\"Distribution for new binary label 'is_hiker'\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos solo dos clases de etiquetas en nuestro conjunto de datos, pero lo hemos hecho aún más desequilibrado.\n",
    "\n",
    "Entrenemos el modelo de bosque aleatorio usando is_hiker como la variable de destino, luego midamos su precisión en los conjuntos de entrenamiento y prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Custom function that measures accuracy on different models and datasets\n",
    "# We will use this in different parts of the exercise\n",
    "def assess_accuracy(model, dataset, label):\n",
    "    \"\"\"\n",
    "    Asesses model accuracy on different sets\n",
    "    \"\"\" \n",
    "    actual = dataset[label]        \n",
    "    predictions = model.predict(dataset[features])\n",
    "    acc = accuracy_score(actual, predictions)\n",
    "    return acc\n",
    "\n",
    "# Split the dataset in an 70/30 train/test ratio. \n",
    "train, test = train_test_split(dataset, test_size=0.3, random_state=1, shuffle=True)\n",
    "\n",
    "# define a random forest model\n",
    "model = RandomForestClassifier(n_estimators=1, random_state=1, verbose=False)\n",
    "\n",
    "# Define which features are to be used (leave color out for now)\n",
    "features = [\"size\", \"roughness\", \"motion\"]\n",
    "\n",
    "# Train the model using the binary label\n",
    "model.fit(train[features], train.is_hiker)\n",
    "\n",
    "print(\"Train accuracy:\", assess_accuracy(model,train, \"is_hiker\"))\n",
    "print(\"Test accuracy:\", assess_accuracy(model,test, \"is_hiker\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión se ve bien tanto para el entrenamiento como para los conjuntos de prueba, pero recuerde que esta métrica no es una medida absoluta del éxito.\n",
    "\n",
    "Deberíamos trazar una matriz de confusión para ver cómo funciona realmente el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn has a very convenient utility to build confusion matrices\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "# Calculate the model's accuracy on the TEST set\n",
    "actual = test.is_hiker\n",
    "predictions = model.predict(test[features])\n",
    "\n",
    "# Build and print our confusion matrix, using the actual values and predictions \n",
    "# from the test set, calculated in previous cells\n",
    "cm = confusion_matrix(actual, predictions, normalize=None)\n",
    "\n",
    "# Create the list of unique labels in the test set, to use in our plot\n",
    "# I.e., ['True', 'False',]\n",
    "unique_targets = sorted(list(test[\"is_hiker\"].unique()))\n",
    "\n",
    "# Convert values to lower case so the plot code can count the outcomes\n",
    "x = y = [str(s).lower() for s in unique_targets]\n",
    "\n",
    "# Plot the matrix above as a heatmap with annotations (values) in its cells\n",
    "fig = ff.create_annotated_heatmap(cm, x, y)\n",
    "\n",
    "# Set titles and ordering\n",
    "fig.update_layout(  title_text=\"<b>Confusion matrix</b>\", \n",
    "                    yaxis = dict(categoryorder = \"category descending\")\n",
    "                    )\n",
    "\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=0.5,\n",
    "                        y=-0.15,\n",
    "                        showarrow=False,\n",
    "                        text=\"Predicted label\",\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=-0.15,\n",
    "                        y=0.5,\n",
    "                        showarrow=False,\n",
    "                        text=\"Actual label\",\n",
    "                        textangle=-90,\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "# We need margins so the titles fit\n",
    "fig.update_layout(margin=dict(t=80, r=20, l=120, b=50))\n",
    "fig['data'][0]['showscale'] = True\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión nos muestra que, a pesar de las métricas reportadas, el modelo no es increíblemente preciso.\n",
    "\n",
    "De las 660 muestras presentes en el conjunto de prueba (30% del total de muestras), predijo 29 falsos negativos y 33 falsos positivos.\n",
    "\n",
    "Más importante aún, mire la fila inferior, que muestra lo que sucedió cuando al modelo se le mostró información sobre un excursionista: se equivocó en la respuesta casi el 30% de las veces. ¡Esto significa que no identificaría correctamente a casi el 30% de las personas en la montaña!\n",
    "\n",
    "¿Qué sucede si usamos este modelo para hacer predicciones sobre conjuntos balanceados?\n",
    "\n",
    "Carguemos un conjunto de datos con la misma cantidad de resultados para \"excursionistas\" y \"no excursionistas\", luego usemos esos datos para hacer predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and print umbiased set\n",
    "#Import the data from the .csv file\n",
    "balanced_dataset = pandas.read_csv('snow_objects_balanced.csv', delimiter=\"\\t\")\n",
    "\n",
    "#Let's have a look at the data\n",
    "graphing.multiple_histogram(balanced_dataset, label_x=\"label\", label_group=\"label\", title=\"Label distribution\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este nuevo conjunto de datos está equilibrado entre las clases, pero para nuestros propósitos queremos que esté equilibrado entre excursionistas y no excursionistas.\n",
    "\n",
    "Para simplificar, tomemos a los excursionistas más una muestra aleatoria de los no excursionistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new label with true/false values to our dataset\n",
    "balanced_dataset[\"is_hiker\"] = balanced_dataset.label == \"hiker\"\n",
    "\n",
    "hikers_dataset = balanced_dataset[balanced_dataset[\"is_hiker\"] == 1] \n",
    "nonhikers_dataset = balanced_dataset[balanced_dataset[\"is_hiker\"] == False] \n",
    "# take a random sampling of non-hikers the same size as the hikers subset\n",
    "nonhikers_dataset = nonhikers_dataset.sample(n=len(hikers_dataset.index), random_state=1)\n",
    "balanced_dataset = pandas.concat([hikers_dataset, nonhikers_dataset])\n",
    "\n",
    "# Plot frequency for \"is_hiker\" labels\n",
    "graphing.multiple_histogram(balanced_dataset, label_x=\"is_hiker\", label_group=\"is_hiker\", title=\"Label distribution in balanced dataset\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede ver, la etiqueta is_hiker tiene el mismo número de Verdadero y Falso para ambas clases. Ahora estamos usando un conjunto de datos balanceado de clases.\n",
    "\n",
    "Ejecutemos predicciones en este conjunto usando el modelo previamente entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model using a balanced dataset\n",
    "actual = balanced_dataset.is_hiker\n",
    "predictions = model.predict(balanced_dataset[features])\n",
    "\n",
    "# Build and print our confusion matrix, using the actual values and predictions \n",
    "# from the test set, calculated in previous cells\n",
    "cm = confusion_matrix(actual, predictions, normalize=None)\n",
    "\n",
    "# Print accuracy using this set\n",
    "print(\"Balanced set accuracy:\", assess_accuracy(model,balanced_dataset, \"is_hiker\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era de esperar, vemos una caída notable en la precisión al usar un conjunto diferente.\n",
    "\n",
    "Nuevamente, analicemos visualmente su desempeño:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot new confusion matrix\n",
    "# Create the list of unique labels in the test set to use in our plot\n",
    "unique_targets = sorted(list(balanced_dataset[\"is_hiker\"].unique()))\n",
    "\n",
    "# Convert values to lower case so the plot code can count the outcomes\n",
    "x = y = [str(s).lower() for s in unique_targets]\n",
    "\n",
    "# Plot the matrix above as a heatmap with annotations (values) in its cells\n",
    "fig = ff.create_annotated_heatmap(cm, x, y)\n",
    "\n",
    "# Set titles and ordering\n",
    "fig.update_layout(  title_text=\"<b>Confusion matrix</b>\", \n",
    "                    yaxis = dict(categoryorder = \"category descending\")\n",
    "                    )\n",
    "\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=0.5,\n",
    "                        y=-0.15,\n",
    "                        showarrow=False,\n",
    "                        text=\"Predicted label\",\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=-0.15,\n",
    "                        y=0.5,\n",
    "                        showarrow=False,\n",
    "                        text=\"Actual label\",\n",
    "                        textangle=-90,\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "# We need margins so the titles fit\n",
    "fig.update_layout(margin=dict(t=80, r=20, l=120, b=50))\n",
    "fig['data'][0]['showscale'] = True\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión confirma la poca precisión con este conjunto de datos, pero ¿por qué sucede esto cuando teníamos métricas tan excelentes en los conjuntos de pruebas y trenes anteriores?\n",
    "\n",
    "Recuérdese que el primer modelo estaba muy desequilibrado. La clase \"excursionista\" representó aproximadamente el 22% de los resultados.\n",
    "\n",
    "Cuando ocurre tal desequilibrio, los modelos de clasificación no tienen suficientes datos para aprender los patrones de la clase minoritaria y, como consecuencia, se sesgan hacia la clase mayoritaria.\n",
    "\n",
    "Los conjuntos desequilibrados se pueden abordar de varias maneras:\n",
    "\n",
    "Mejora de la selección de datos<br>\n",
    "Remuestreo del conjunto de datos<br>\n",
    "Uso de clases ponderadas<br>\n",
    "Para este ejercicio, nos centraremos en la última opción.\n",
    "\n",
    "Uso de ponderaciones de clase para equilibrar el conjunto de datos\n",
    "Podemos asignar diferentes pesos a las clases mayoritarias y minoritarias, según su distribución, y modificar nuestro algoritmo de entrenamiento para que tenga en cuenta esa información durante la fase de entrenamiento.\n",
    "\n",
    "Luego, penalizará los errores cuando la clase minoritaria esté mal clasificada, en esencia, \"forzando\" al modelo a aprender mejor sus características y patrones.\n",
    "\n",
    "Para usar clases ponderadas, tenemos que volver a entrenar nuestro modelo usando el conjunto de trenes original, pero esta vez diciéndole al algoritmo que use pesos al calcular los errores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import function used in calculating weights\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Retrain model using class weights\n",
    "# Using class_weight=\"balanced\" tells the algorithm to automatically calculate weights for us\n",
    "weighted_model = RandomForestClassifier(n_estimators=1, random_state=1, verbose=False, class_weight=\"balanced\")\n",
    "# Train the weighted_model using binary label\n",
    "weighted_model.fit(train[features], train.is_hiker)\n",
    "\n",
    "print(\"Train accuracy:\", assess_accuracy(weighted_model,train, \"is_hiker\"))\n",
    "print(\"Test accuracy:\", assess_accuracy(weighted_model, test, \"is_hiker\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de usar las clases ponderadas, la precisión del tren se mantuvo casi igual, mientras que la precisión de la prueba mostró una pequeña mejora (aproximadamente el 1 %).\n",
    "\n",
    "Veamos si los resultados mejoran usando el conjunto balanceado para predicciones nuevamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Balanced set accuracy:\", assess_accuracy(weighted_model, balanced_dataset, \"is_hiker\"))\n",
    "\n",
    "# Test the weighted_model using a balanced dataset\n",
    "actual = balanced_dataset.is_hiker\n",
    "predictions = weighted_model.predict(balanced_dataset[features])\n",
    "\n",
    "# Build and print our confusion matrix, using the actual values and predictions \n",
    "# from the test set, calculated in previous cells\n",
    "cm = confusion_matrix(actual, predictions, normalize=None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión del conjunto equilibrado aumentó aproximadamente un 4 %, pero aun así deberíamos tratar de visualizar y comprender los nuevos resultados.\n",
    "\n",
    "Matriz de confusión final\n",
    "Ahora podemos trazar una matriz de confusión final, que representa predicciones para un conjunto de datos equilibrado, utilizando un modelo entrenado en un conjunto de datos de clase ponderada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the matrix above as a heatmap with annotations (values) in its cells\n",
    "fig = ff.create_annotated_heatmap(cm, x, y)\n",
    "\n",
    "# Set titles and ordering\n",
    "fig.update_layout(  title_text=\"<b>Confusion matrix</b>\", \n",
    "                    yaxis = dict(categoryorder = \"category descending\")\n",
    "                    )\n",
    "\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=0.5,\n",
    "                        y=-0.15,\n",
    "                        showarrow=False,\n",
    "                        text=\"Predicted label\",\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
    "                        x=-0.15,\n",
    "                        y=0.5,\n",
    "                        showarrow=False,\n",
    "                        text=\"Actual label\",\n",
    "                        textangle=-90,\n",
    "                        xref=\"paper\",\n",
    "                        yref=\"paper\"))\n",
    "\n",
    "# We need margins so the titles fit\n",
    "fig.update_layout(margin=dict(t=80, r=20, l=120, b=50))\n",
    "fig['data'][0]['showscale'] = True\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien los resultados pueden parecer un poco decepcionantes, ahora tenemos un 21 % de predicciones incorrectas (FN + FP), frente al 25 % del experimento anterior.\n",
    "\n",
    "Las predicciones correctas (TPs + TNs) pasaron del 74,7% al 78,7%.\n",
    "\n",
    "¿Es significativa o no una mejora general del 4%?\n",
    "\n",
    "Recuerde que teníamos relativamente pocos datos para entrenar el modelo, y las funciones que tenemos disponibles aún pueden ser tan similares para diferentes muestras (por ejemplo, los excursionistas y los animales tienden a ser pequeños, no bruscos y se mueven mucho), que a pesar de nuestra esfuerzos, el modelo todavía tiene algunas dificultades para hacer predicciones correctas.\n",
    "\n",
    "Solo tuvimos que cambiar una sola línea de código para obtener mejores resultados, ¡así que parece que vale la pena el esfuerzo!\n",
    "\n",
    "Resumen\n",
    "\n",
    "Este fue un ejercicio largo, donde cubrimos los siguientes temas:\n",
    "\n",
    "Creando nuevos campos de etiqueta para que podamos realizar una clasificación binaria usando un conjunto de datos con múltiples clases.<br>\n",
    "Cómo el entrenamiento en conjuntos desequilibrados puede tener un efecto negativo en el rendimiento, especialmente cuando se utilizan datos ocultos de conjuntos de datos equilibrados.<br>\n",
    "Evaluación de resultados de modelos de clasificación binaria utilizando una matriz de confusión.<br>\n",
    "Uso de clases ponderadas para abordar los desequilibrios de clase al entrenar un modelo y evaluar los resultados."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
